[["przedmiot-metody-i-organizacja-badań-statystycznych.html", "Wprowadzenie do statystyki dla ekonomistów 1 Przedmiot, metody i organizacja badań statystycznych 1.1 Przedmiot statystyki 1.2 Pomiar 1.3 Rodzaje badań statystycznych 1.4 Organizacja badań statystycznych 1.5 Opracowanie danych", " Wprowadzenie do statystyki dla ekonomistów Tomasz Przechlewski Powiślańska Szkoła Wyższa (Kwidzyn-Gdańsk) t.plata-przechlewski@psw.kwidzyn.edu.pl 1 Przedmiot, metody i organizacja badań statystycznych 1.1 Przedmiot statystyki Statystyka: analiza struktury, przedziały ufności i weryfikacja hipotez, analiza współzależności. Etapy analizy statystycznej: – przełóż obserwacje na postać liczbową – wnioskuj (zastosuj odpowiednie statystyki) Analiza eksploracyjna Exploratory research is the stage of the research process that aims at connecting ideas as to unveil the ``why’’s of potential cause/effect relationships. This occurs when researchers get started at understanding what they are actually observing when in the process of building cause/effect models. Analiza konfirmacyjna Confirmatory research (a.k.a. hypothesis testing) is where researchers have a pretty good idea of what’s going on. That is, researcher has a theory (or several theories), and the objective is to find out if the theory is supported by the facts. Data wrangling, sometimes referred to as data munging, is the process of transforming and mapping data from one raw data form into another format with the intent of making it more appropriate and valuable for a variety of downstream purposes such as analytics. Data science also known as data-driven science, is an interdisciplinary field of scientific methods, processes, algorithms and systems to extract knowledge or insights from data in various forms, either structured or unstructured. Opis statystyczny – liczbowe przedstawienie badanych zbiorowości lub zjawisk w postaci opisu: – tabelarycznego; – graficznego; – parametrycznego Opis statystyczny może dotyczyć: – struktury zbiorowości; – współzależności; – zmian zjawisk w czasie. Badanie statystyczne to zespół czynności zmierzających do uzyskania (za pomocą metod statystycznych) informacji charakteryzujących badaną zbiorowość lub zjawisko. Najważniejsze kryteria klasyfikacji badań: – zakres obserwacji badanych jednostek (pełne, częściowe); – częstotliwość: (ciągłe, okresowe, doraźne); – zasięg przestrzenny (międzynarodowe, krajowe, regionalne, środowiskowe, monograficzne); – dziedzina badań (demograficzne, społeczne, ekonomiczne, rolnicze, jakości środowiska naturalnego itp. Populacja, zbiorowość statystyczna: zbiór obiektów (osób, przedmiotów, zdarzeń) logicznie ze sobą powiązanych (ale nie identycznych), poddany badaniu statystycznemu. Jednostka statystyczna: jednostki statystyczne w danej populacji różnią się od innych jednostek spoza danej populacji poprzez swoje własności wspólne (cechy stałe), jednocześnie różnią się między sobą cechami (cechy zmienne), które są przedmiotem zainteresowania badacza. Cechy statystyczne – właściwości jednostek statystycznych Cechy stałe – jednakowe dla wszystkich jednostek badania: rzeczowa (co? kto? jest badane/y) przestrzenna (gdzie?) czasowa (kiedy?) Cechy zmienne – właściwości różnicujące jednostki jednostki z badanej populacji, tj. takie które mogą posiadać więcej niż 1 wariant (jeżeli posiadają jeden mamy do czynienia z przypadkiem trywialnym). Cechy zmienne dzielimy na: – jakościowe (płeć, rok studiów) – ilościowe (wiek) Pojęcia stosowane w statystyce publicznej https://stat.gov.pl/metainformacje/slownik-pojec/pojecia-stosowane-w-statystyce-publicznej/lista.html 1.2 Pomiar Pomiar (zwany też obserwacją) – przyporządkowanie wariantom cechy zmiennej liczb lub symboli. W naukach przyrodniczych (fizyka, chemia) pomiaru dokonuje przy zastosowaniu precyzyjnych/jednoznacznie określonych definicji miar. W naukach społecznych jest niestety inaczej: wiele definicji jest nieprecyzyjnych (na przykład turysta albo emigrant), a wiele miar przybliżonych. Przy czym brak precyzji nie wynika z błędu pomiaru (źle przyłożona linijka), ale jest cechą użytej skali pomiarowej (nieprecyzyjna linijka). Rodzaje skal pomiarowych nominalna (nominal scale), klasyfikuje: płeć; porządkowa (ordinal scale), klasyfikuje i porządkuje: zdolność kredytowa firmy, stadia choroby, – przedziałowa (interval scale), posiada jeszcze stałą jednostkę miary (ów przedział) oraz umowne zero (temperatura w stopniach Celsjusza) – ilorazowa (rational scale), posiada to co przedziałowa plus naturalne zero (wiek, wzrost, obrót, temperatura w stopniach Kelwina). Skala Kelvina temperatury jest ilorazowa, skala Celsiusza jest przedziałowa. Zero w skali Kelvina to zero bezwzględne, 200K jest 2 razy mniejsze niż 400K podczas gdy 200C nie jest dwa razy mniejsze niż 400C. Na skali przedziałowej nie można w bezpieczny sposób dokonywać dzielenia. Na liczbach w skali porządkowej nie można dokonywać nawet dodawania. Wszystkie operacje arytmetyczne są bezpieczne tylko dla skali ilorazowej. Cecha statystyczna mierzalna (ilościowa) – określana jest za pomocą liczb np. oceny, płace. Cechy mierzalne dzielą się na skokowe i ciągłe. Skokowe są to cechy, które przyjmują skończoną liczbę wartości, zwykle są to liczby całkowite; Ciągłe są to cechy, które przyjmują dowolne wartości liczbowe z pewnego przedziału liczbowego np. dochody, długość ziarna fasoli. 1.3 Rodzaje badań statystycznych Pełne (spis, rejestracja), częściowe (reprezentacyjne), szacunki interpolacyjne i ekstrapolacyjne (ustalenie wartości na podstawie znanych wartości podobnych/poprzednich/sąsiednich; wbrew pozorom często stosowana metoda). Ciągłe (ewidencja urodzeń), okresowe (spisy rolne, spis powszechny), doraźne (sondaż poparcia w wyborach prezydenckich) Spis to gromadzenie danych na potrzeby badania; Rejestracja to gromadzenie danych przy okazji wykonywania innych działań (ewidencja ludności, działanie wymiaru sprawiedliwości, gromadzenie danych pogodowych itp…) Badanie reprezentacyjne to badanie oparte na próbie pobrane ze zbiorowości w taki sposób, że wyniki uzyskane dla tej próby można uogólnić na całą populację (wymaga to odpowiedniego sposobu wybrania jednostek do próby; nie każda próba jest reprezentacyjna) 1.4 Organizacja badań statystycznych Etapy wstępne badania statystycznego: ustalenie celu i metody (pełne częściowe); określenie zbiorowości i jednostki badania; określenie cech/wartości cech podlegających gromadzeniu (definiowanie/klasyfikacja) oraz sposobu pomiaru; zdefiniowanie jednostki sprawozdawczej (od kogo pozyskamy dane). Klasyfikacja to ustalenie (wyodrębnienie) wariantów cechy. Cechy/wartości cech nie mogą być wymyślane ad hoc ale (w imię porównywalności) powinny być definiowane z użyciem powszechnie stosowanych słowników/taksonomii/klasyfikacji (TERYT, PESEL, EKD) Kto to jest turysta? Co to jest hotel? Co to jest las? Materiał pierwotny (dane zgromadzone specjalnie dla celów badania), materiał wtórny (dane zgromadzone z innych powodów ale przydatne do badania statystycznego; dane rejestrowane). Wg Sobczaka (2024): większą wartość mają materiały pierwotne, ponieważ są aktualne, gromadzone z określoną dokładością i nie są obciążone zbytecznymi informacjami. Powyższe można uznać za mocno nieaktualne. Współcześnie dane z rejestrów są coraz zarówno lepsze jakościowo jak i dominują ilościowo (Facebook/Google najlepszym przykładem). 1.5 Opracowanie danych Grupowanie – podział zbiorowości na jednorodne lub względnie jednorodne podgrupy z punktu widzenia wyróżnionej cechy (cech): – typologiczne (cechy jakościowe); – wariancyjne (cechy ilościowe). Zasady logiki formalnej: grupowanie musi być wyczerpujące – każda jednostka zbiorowości musi być sklasyfikowana i włączona do odpowiedniej podgrupy; – grupowanie powinno być rozłączne – wyodrębnione podgrupy muszą się wzajemnie wykluczać; – grupowanie powinno być efektywne – wyróżnione podgrupy powinny być na tyle jednorodne jakościowo, by mogły stanowić podstawę twierdzeń uogólniających Szereg statystyczny to zbiór wyników obserwacji (pomiaru) pewnej cechy. Jeżeli pomiaru dokonano na zbiorze jednostek to mówimy o szeregu przekrojowym lub strukturalnym (mierzymy wiele jednostek w pewnym momencie/okresie czasu), jeżeli pomiar dotyczy jednostki, a nie zbioru, ale dokonany został w kolejnych momentach/okresach czasu, to mówimy o szeregu czasowym. Jeżeli zbiór mierzonych jednostek zawiera informacje o ich położeniu na powierzchni Ziemi (np. współrzędne geograficzne), to mówimy o szeregu przestrzennym. Zamiast szereg używa się teminu dane (dane przekrojowe/czasowe/przestrzenne) Reasumując: szereg strukturalny przestawia rozkład wartości cechy w pewnej zbiorowości (strukturę stąd nazwa); szereg czasowy określa zmianę wartości cechy w czasie, zaś szereg przestrzenny rozkład wartości cechy na powierzchni Ziemi. Szereg przekrojowy/przestrzenny może być szczegółowy lub rozdzielczy. Szereg jest szczegółowy jeżeli tworzący go zbiór wartości zostanie uporządkowany (według wartości cechy) Szereg jest rozdzielczy jeżeli zostanie pogrupowany i uporządkowany tj. zostanie zamieniony na uporządkowane pary (cecha–liczebność cechy) Szereg czasowy może być szeregiem okresów (strumieni) lub momentów (stanów). Przykładowo: liczba urodzeń żywych w powiecie kwidzyńskim w latach 2000–2019, to szereg czasowy okresów (strumieni); w szczególności można dodać liczbę urodzeń w poszczególnych latach otrzymując łączną liczbę urodzonych w tym okresie. Liczba zarejestrowanych pojazdów w powiecie kwidzyńskim w latach 2000–2019 to szereg momentów (stan); nie można sumować liczby zarejestrowanych samochodów, bo taka suma nie ma merytorycznie sensu. Można podać średnią (przeciętny stan) zarejestrowanych samochodów w latach 2000–2019. Wiele danych ekonomiczno-społecznych jest mierzonych na poziomie jednostek administracyjnych (gmina, powiat, województwo, państwo). Formalnie taki zbiór danych jest szeregiem przestrzennym. "],["analiza-struktury.html", "2 Analiza struktury 2.1 Tablice statystyczne 2.2 Rozkład empiryczny 2.3 Rozkład normalny 2.4 Wizualizacja danych i wykresy 2.5 Analiza parametryczna", " 2 Analiza struktury Analiza struktury – opisane zbiorowości ze względu na obserwowane w badaniu cechy zmienne. Podstawę do oceny struktury zbiorowości stanowią dane w postaci szeregu szczegółowego, bądź też pogrupowane (szereg rozdzielczy) Analizę prowadzić można na podstawie wykresów, szeregów rozdzielczych oraz (najczęściej) za pomocą odpowiednio obliczonych charakterystyk, zwanych parametrami (dla populacji) lub statystykami (dla próby). Rozkład cechy – przyporządkowanie liczby wystąpień (liczebności, częstości lub prawdopodobieństwa) odpowiednim wartościom cechy zmiennej. Analiza struktury obejmuje: określenie tendencji centralnej (tzw. miary położenia / wartość przeciętna, mediana, dominanta); zróżnicowanie wartości (rozproszenie); asymetrię (rozłożenie wartości wokół średniej); koncentrację (podział wartości cechy pomiędzy jednostki) 2.1 Tablice statystyczne Tablica statystyczna to (w podstawowej formie) dwukolumnowa tabela zawierająca wartości cechy oraz odpowiadające tym wartościom liczebności. Przykład 1: Tablica dla cechy niemierzalnej (nominalnej albo porządkowej) Absolwenci studiów pielęgniarskich w ośmiu największych krajach UE w roku 2018 Jednostka badania: absolwent studiów pielęgniarskich w roku 2018, Badana cecha: kraj w którym ukończył studia (nominalna) Tablica: Absolwenci studiów pielęgniarskich w ośmiu największych krajach UE w roku 2018 kraj liczba Belgium 7203 Germany 35742 Spain 9936 France 25757 Italy 11207 Netherlands 9920 Poland 9070 Romania 18664 Źródło: Eurostat, tablica Health graduates (HLTH_RS_GRD) Przykład 2: Tablica dla cechy mierzalnej (liczbowej; skokowej lub ciągłej) Jeżeli liczba wariantów cechy jest mała tablica zawiera wyliczenie wariantów cechy i odpowiadających im liczebności. Jeżeli liczba wariantów cechy jest duża tablica zawiera klasy wartości (przedziały wartości) oraz odpowiadające im liczebności. Co do zasady klasy wartości powinny być jednakowej rozpiętości. Na zasadzie wyjątku dopuszcza się aby pierwszy i ostatni przedział były otwarte, tj. nie miały dolnej (pierwszy) lub górnej (ostatni) granicy Tablica: Gospodarstwa domowe we wsi X wg liczby samochodów w roku 2022 liczba samochodów liczba gospodarstw % 0 230 39.3162393 1 280 47.8632479 2 70 11.9658120 3 i więcej 5 0.8547009 razem 585 100.0000000 Źródło: obliczenia własne Tablica dla cechy mierzalnej (liczbowej ciągłej–wymaga pogrupowania w klasy): Przykład: Dzietność kobiet na świecie Współczynnik dzietności (fertility ratio albo FR) – przeciętna liczba urodzonych dzieci przypadających na jedną kobietę w wieku rozrodczym (15–49 lat). Przyjmuje się, iż FR między 2,10–2,15 zapewnia zastępowalność pokoleń. Dane dotyczące dzietności dla wszystkich krajów świata można znaleźć na stronie https://ourworldindata.org/grapher/fertility-rate-complete-gapminder) Zbudujmy tablicę przedstawiającą rozkład współczynników dzietności w roku 2018 Krajów jest 201. Wartość minimalna to 1.22 a wartość maksymalna to 7.13. Decydujemy się na rozpiętość przedziału równą 0,5; dolny koniec pierwszego przedziału przyjmujemy jako 1,0. Zwykle przyjmuje się za końce przedziałów okrągłe liczby bo dziwnie by wyglądało gdyby koniec przedziału np. był równy 1,05 zamiast 1,0. Liczba przedziałów jest dobierana metodą prób i błędów, tak aby: nie było przedziałów z zerową liczebnością przedziałów nie było za dużo ani za mało (typowo 8–15) większość populacji nie znajdowała się w jednej czy dwóch przedziałach Tablica: Kraje świata według współczynnika dzietności (2018) Wsp. dzietności liczba krajów (1,1.5] 24 (1.5,2] 61 (2,2.5] 40 (2.5,3] 17 (3,3.5] 8 (3.5,4] 15 (4,4.5] 11 (4.5,5] 12 (5,5.5] 6 (5.5,6] 5 (6,6.5] 1 (7,7.5] 1 Źródło: https://ourworldindata.org/grapher/fertility-rate-complete-gapminder Każda tablica statystyczna musi mieć: Część liczbową (kolumny i wiersze); żadna rubryka w części liczbowej nie może być pusta (żelazna zasada); w szczególności brak danych należy explicite zaznaczyć umownym symbolem Część opisową: tytuł tablicy; nazwy (opisy zawartości) wierszy; nazwy (opisy zawartości) kolumn; wskazanie źródła danych; ewentualne uwagi odnoszące się do danych liczb. Pominięcie czegokolwiek z powyższego jest ciężkim błędem. Jeżeli nie ma danych (a często nie ma–z różnych powodów – należy to zaznaczyć a nie pozostawiać pustą rubrykę) 2.2 Rozkład empiryczny Rozkład empiryczny zmiennej to przyporządkowanie wartościom zmiennej odpowiadających im liczebności lub częstości (czyli udziału procentowego w całości). Jak taki rozkład wygląda? Rozkład wiek laureatów nagrody Nobla (od 1901 roku do 2018, N=934). Rozkład wieku zawodników, którzy brali udział w turniejach o Puchar Świata w Rugby w latach 1999-2019 (N= 3649). Rozkłady powiatów w Polsce wg powierzchni (stan na 2017, N=380); bez powiatów miejskich po prawej (N=380 - 66) Rozkład powiatów Polsce wg liczby hoteli (stan na 2017, N=380) Rozkład elektrowni w Niemczech/Francji/Wlk Brytanii wg mocy (Mgw, stan na 2019, N=4586) Dane dotyczące elektrowni pochodzą z bazy http://datasets.wri.org/dataset/globalpowerplantdatabase Rozkłady liczebności i częstości mogą mieć postać rozkładów skumulowanych. Rozkład skumulowany to przyporządkowanie dla każdej wartości zmiennej odpowiadającej jej liczebności oraz liczebności wszystkich wartości mniejszych od tej wartości (potocznie: dla każdego x liczba obserwacji o wartości nie większej od x). Liczebność skumulowana dla wartości maksymalnej jest równa liczebności populacji (lub 100% dla rozkładu częstości.) Przykład: wiek zawodników którzy brali udział w turniejach o Puchar Świata w Rugby w latach 1999-2019 (rozkład liczebności, skumulowany liczebności, częstości oraz skumulowany częstości) ## wiek N cum proc cumproc ## 18 1 1 0.027 0.027 ## 19 8 9 0.219 0.247 ## 20 37 46 1.015 1.261 ## 21 86 132 2.358 3.619 ## 22 155 287 4.250 7.869 ## 23 239 526 6.553 14.423 ## 24 296 822 8.116 22.539 ## 25 354 1176 9.707 32.246 ## 26 370 1546 10.145 42.391 ## 27 381 1927 10.447 52.838 ## 28 350 2277 9.597 62.435 ## 29 337 2614 9.240 71.675 ## 30 300 2914 8.226 79.901 ## 31 226 3140 6.197 86.098 ## 32 176 3316 4.826 90.924 ## 33 142 3458 3.894 94.818 ## 34 97 3555 2.660 97.477 ## 35 51 3606 1.398 98.876 ## 36 19 3625 0.521 99.397 ## 37 12 3637 0.329 99.726 ## 38 9 3646 0.247 99.973 ## 39 0 3646 0.000 99.973 ## 40 1 3647 0.027 100.000 Czyli przykładowo było 381 zawodników w wieku 27 lat, albo 1927 zawodników w wieku 27 i mniej lat, albo zawodnicy w wieku 27 lat stanowili 10.447% wszystkich uczestników turnieju, albo zawodnicy w wieku 27 lat i mniej stanowili 52.838% wszystkich uczestników turnieju. 2.3 Rozkład normalny Cecha mierzalna ciągła to na przykład wiek mierzony z nieskończoną dokładnością. Istnieje funcja określona formułą: \\[f(x) = \\frac{1}{s \\sqrt{2 \\pi}} \\cdot \\exp(-(x -m)^2/2s^2)\\] zwana rozkładem normalnym, która może interpolować wiele rozkładów empirycznych. Właściwością tej funkcji jest, że jej kształt jest zdefiniowany jedynie przez dwa parametry: \\(m\\) jest średnią wartością, a \\(s\\) jest odchyleniem standardowym (co to jest odchylenie standardowe wyjaśniamy dalej). Zatem mając rozkład empiryczny można policzyć średnią oraz odchylenie standardowe i w ten sposób wyznaczyć konkrety wariant rozkładu normalnego. Przykładowo poniżej przedstawiono rozkład empiryczny wieku laureatów nagrody Nobla: niebieska krzywa to rozkład Normalny (o średniej 59.8469274 oraz odchyleniu standardowym 12.3913637). Wiele rozkładów empirycznych spotykanych w otaczającej nas rzeczywistości jest zbliżonych do rozkładu normalnego (wiek, waga, błąd pomiaru, długość itd), ale wiele zjawisk ekonomiczno-społecznych nie jest. Przykładowo poniżej przedstawiono rozkład empiryczny miast w Polsce ze względu na liczbę mieszkańców (dane za Wikipedią) Fioletowa krzywa to rozkład normalny o średniej 24465.0 oraz odchyleniu standardowym 81404.0. Aproksymacja jest taka-sobie mówiąc oględnie… Tego typu rozkładu z kolei dobrze aproksymuje inny rozkład, określany jako logarytmiczno-normalny, w którym zamiast oryginalnej wartości cechy używa się logarytmu wartości. Rozkład wielkości miast aproksymowany rozkładem logarytmiczno-normalnym przedstawia następny przykład: Jest mało dużych miast a dużo małych. Podobnie wyglądają rozkłady firm/ludzi względem przychodów/zysków czy elektrowni względem mocy zainstalowanej. 2.4 Wizualizacja danych i wykresy Wykresy statystyczne są graficzną formą prezentacji materiału statystycznego, są mniej precyzyjne i szczegółowe niż tablice, natomiast bardziej sugestywne. Rodzaje wykresów (podział ze względu na zastosowanie): Jedna cecha szeregi strukturalne: punktowe, słupkowe, histogram, pudełkowe, kołowe; szeregi czasowe: liniowe, słupkowe, punktowe; szeregi przestrzenne: kartogramy. Dwie cechy wykres rozrzutu (scatter-plot), wykres liniowy liniowy 2.4.1 Wykresy przedstawiające rozkład wartości jednej zmiennej Celem jest pokazanie rozkładu wartości cechy w populacji: jakie wartości występują często a jakie rzadko, jak bardzo wartości różnią się między sobą. Jak różnią się rozkłady dla różnych ale logicznie powiązanych populacji (np rozkład czegoś-tam w kraju A i B albo w roku X, Y i Z). Do tego celu stosuje się: histogram (albo wykres słupkowy dla skal nominalnych), wykres punktowy, wykres pudełkowy oraz kołowy. Omówimy je na przykładach 2.4.2 Histogram Współczynnik dzietności – przeciętna liczba urodzonych dzieci przypadających na jedną kobietę w wieku rozrodczym (15–49 lat). Przyjmuje się, iż FR między 2,10–2,15 zapewnia zastępowalność pokoleń. Plik fertility_rate_2003_2018.csv (źródło: https://ourworldindata.org/grapher/fertility-rate-complete-gapminder) zawiera wartości współczynnika w roku 2003 oraz 2018 (czyli po 15 latach) dla 202 krajów. Do oceny rozkładu wartości zmiennej służy histogram (por https://pl.wikipedia.org/wiki/Histogram). Jeżeli umieścimy obok siebie dwa (lub więcej) histogramy, możemy w ten sposób porównać (wizualnie) dwa rozkłady: Kształt histogramu zależy od wyboru rozpiętości przedziału; im przedział węższy tym więcej słupków (ale ich wysokość będzie mniejsza). Poniżej przedstawiono ten sam rozkład dla rozpiętości przedziału równej odpowiednio 0,1, 0,25 oraz 0,5: Dlatego jeżeli porównujemy różne rozkłady za pomocą umieszczonych obok siebie histogramów to powinny one mieć: tę samą rozpiętość przedziałów, te same skale na obu osiach. Istnieją wzory na optymalną liczbę przedziałów ale nalepszą metodą jest metoda prób i błędów. 2.4.3 Wykres punktowy Czasami jeżeli liczebność populacji nie jest za duża można spróbować przedstawić rozkład cechy na wykresie punktowym: 2.4.4 Porównanie wielu rozkładów Jeżeli używamy histogramu to w zasadzie jedyną opcją jest wykreślenie każdego histogramu oddzielnie a następnie umieszczenie ich obok siebie. Wyjątkowo można spróbować wykreślić dwa na jednym wykresie (jeżeli program, którym się posługujemy umożliwia rysowanie kolorem przeźroczystym): Łącznie na jednym wykresie (wykres punktowy): 2.4.5 Wykresy kołowe Dane pochodzą z bazy danych Eurostatu są dostępne pod adresem https://appsso.eurostat.ec.europa.eu/nui/show.do?dataset=tour_occ_nim&amp;lang=en Nights spent at tourist accommodation establishments by non residents (id tabeli: tour_occ_ninat) czyli po polsku Noclegi udzielone w turystycznych obiektach noclegowych (https://ec.europa.eu/eurostat/web/products-datasets/-/tin00175; https://stat.gov.pl/metainformacje/slownik-pojec/pojecia-stosowane-w-statystyce-publicznej/1233,pojecie.html; https://stat.gov.pl/en/metainformations/glossary/terms-used-in-official-statistics/1233,term.html) Poniższy rysunek przedstawia typową tabelę (wielowymarową) z danymi dotyczącymi wykorzystania miejsc noclegowych w krajach UE. Nagłówek tabeli: TIME, GEO, Unit of measure, Classification of economic activities, Country of residencie definiuje cechy stałe zbiorowści statystycznej. Dla każdej cechy zwykle możliwy jest wybór z kilku dostępnych wariantów. Tabela na rysunku przedstawia dane roczne, dla krajów UE, dotyczące liczby noclegów w hotels, holidays and other short-stay accomodations, camping grounds, recreational vehicle parks and trailes parks (Hotele, Obiekty noclegowe turystyczne i miejsca krótkotrwałego zakwaterowania, Pola kempingowe, włączając pola dla pojazdów kempingowych i pola namiotowe; https://ec.europa.eu/eurostat/ramon/nomenclatures/index.cfm). Skrót NACE oznacza klasyfikację działalności gospodarczej, która służy do określenia jakie miejsca noclegowe są uważane za turystyczne (bo to nie jest oczywiste). Liczbę noclegów dla 10 najczęściej odwiedzanych przez turystów krajów (oraz dla reszty oznaczonej jako Rest28) przestawiono na wykresie kołowym (https://pl.wikipedia.org/wiki/Diagram_ko%C5%82owy). Wielkość każdego wycinka koła (pole tego wycinka albo, kąt) jest proporcjonalna do liczby noclegów w danym kraju. Stąd wykres kołowy wizualizuje udział (popularnie zwany procentem) każdego wycinka w całości. Możemy dodać etykiety zawierające albo ów udział (prawy wariant na przykładzie poniżej); albo oryginalne liczby. Wykres pokazuje dobitnie wszystkie wady wykresu kołowego: niemożliwe jest określnie różnic pomiędzy wycinkami, chybna że różnice te są ogromne. Np niemożliwe jest ustalenie czy jak bardzo różni się udział w UK i Francji. Albo czy liczba noclewgów w Austrii jest mniejsza/większa/równa niż w Niemczech, itd… Jeżeli dodamy liczby to sprawa się wyjaśni (prawy wariant) tylko po co wtedy rysunek? Znacznie bardziej efektywne są wykresy punktowe (lewy) lub słupkowe (prawy): Dużo lepiej widać różnice pomiędzy krajami. Niepotrzebna jest legenda. Nazwy krajów są na osi OY, liczba noclegów na osi OX. Na wykresie kołowym albo w wycinku mieściła się nazwa kraju albo procent nie było miejsca dla obu, stąd potrzebna była legenda (utrudniająca interpretację) Wniosek: każdy wykres kołowy można i TRZEBA zamienić na słupkowy. Wykresów kołych nie należy stosować bo są znacznie gorszym sposobem wizualizacji informacji niż słupkowe. 2.4.6 Wykres pudełkowy Uwaga: poniższy opis wykresu pudełkowego zawiera pojęcia jeszcze nie wyjaśnione (kwartyle, mediana, rozproszenie i IQR), które opisano dokładanie dalej, w punktach miary położenia/miary zmienności. Konstrukcja pudełka na wykresie: górny/dolny bok równy kwartylom, a linia pozioma w środku pudełka równa medianie; linie pionowe (zwane wąsami) mają długość równą Q1 minus 1,5 IQR oraz Q3 plus IQR (Q1, Q3 to kwartyle, IQR to odstęp między kwartlowy; co to jest kwartyl, mediana i odstęp międzykwartylowy jest wyjaśnione poniżej); Linia pozioma w połowie pudełka określa przeciętny poziom zjawiska; wysokość pudełka/wąsów określa zmienność (im większe wąsy/wysokość tym większa zmienność). Obserwacje nietypowe (czyli takie których wartość jest albo mniejsza od \\(Q1 - 1,5IQR\\) albo większa od \\(Q3 + 1,5IQR\\))są zaznaczana indywidualnie jako kropki nad/pod wąsami. Ze strony komiteu Noblowskiego pobrano listę Laureatów Nagrody Nobla Wiek laureatów nagrody Nobla w momencie przyznania nagrody (ponad 900 laureatów; plik nobel_laureates3.csv): Najstarsi przeciętnie: ekonomia; najmłodsi przeciętnie: fizyka. Najmniejsze zróżnicowanie: ekonomia; największe zróżnicowanie: fizyka. Nie ma szans na nobla (koniec dolnego wąsa) przed pięćdziesiątką w ekonomii, przed 40-tką w literaturze, przed trzydziestką w chemii, medycynie i nagrodzie pokojowej. Wykres niezwykle użyteczny do porównywania różnic w rozkładach wartości cechy. 2.4.7 Wykres skrzypcowy (wariant wykresu pudełkowego) In general, violin plots are a method of plotting numeric data and can be considered a combination of the box plot with a kernel density plot. In the violin plot, we can find the same information as in the box plots: – median; – interquartile range; – the lower/upper adjacent values (defined as first quartile — 1.5 IQR and third quartile + 1.5 IQR respectively.) Jako ilustrację przedstawmy rozkłady elektrowni (http://datasets.wri.org/dataset/globalpowerplantdatabase) w podziale na wykorzystywane paliwo: numlearnych, solarnych, na biomasę oraz węglowych. Nukleane (rozkład w miarę symetryczny/jednomodalny.) Zwróćmy uwagę, że wykres skrzypcowy zachowuje kształt dzwonu tyle, że podwojonego: dwa szpiczaste końce i wybrzuszenie w środkowej części. Solarne (rozkład skrajnie asymetryczny) Wykres skrzypcowy dla wykresu asymetrycznego ma tylko jeden szpic. Na biomasę (także asymetryczny ale o asymetrii mniejszej niż poprzedni) Węglowe (wielomodalny/asymetria lewostronna) Kształt wykresu skrzypcowego dla rozkładu wielomodalnego jest pofalowany. Współczynnik dzietności w latach 2003/2018 oraz współczynniki dzietności na poszczególnych kontynentach (w roku 2018) 2.4.8 Przykład: Zaufanie do Politykow CBOS realizuje co najmniej 12 razy w roku sondaż “Aktualne problemy i wydarzenia”, na reprezentatywnej ok. 1000-osobowej próbie dorosłych mieszkańców Polski. (cf https://www.cbos.pl/PL/trendy/trendy.php?) Częścią tych badań jest badanie zaufania do Polityków. Które to zaufanie jest mierzone w taki sposób, że respondenci odpowiadają na jedno pytanie, które brzmi: Ludzie aktywni publicznie – swoim zachowaniem, tym, co mówią, do czego dążą – budzą mniejsze lub większe zaufanie. Przedstawimy teraz Panu(i) listę osób aktywnych w życiu politycznym naszego kraju. O każdej z nich proszę powiedzieć, w jakim stopniu budzi ona Pana(i) zaufanie. Odpowiadając, proszę posłużyć się skalą, na której –5 oznacza, że osoba ta budzi w Panu(i) głęboką nieufność, 0 – że jest ona Panu(i) obojętna, a +5 oznacza, że ma Pan(i) do tej osoby pełne zaufanie. Oczywiście może się Pan(i) posługiwać innymi ocenami tej skali. Jeżeli kogoś Pan(i) nie zna, proszę powiedzieć Odsetki badanych wyrażających zaufanie – wskazania punktów od +1 do +5, nieufność – wskazania punktów od –1 do –5, obojętność – 0 W zestawieniu CBOS pomija odpowiedzi „trudno powiedzieć” i odmowy odpowiedzi. Analiza CBOS (przykład raportu jest w pliku zaufanie_do_politykow_CBOS_2019.pdf) posługuje się skumulowanym wykresem słupkowym (stacked barchart): Skumulowany wykres słupkowy jest w zasadzie jest wykresem kołowym, tyle że zamiast kółek są prostokąty (cf https://eagereyes.org/techniques/stacked-bars-are-the-worst). Można łatwo porównywać łączną wartość albo wartość przedstawioną za pomocą pierwszego słupka (bo mają wspólną linię dla wartości zero, common baseline). Pozostałe słupki nie są oparte o wspólną linię zerowej wartości i w związku z tym porównanie ich wartości jest trudne. W przykładzie każdy słupek ma 3 kategorie a już jest trudno wskazać czy nieufność do Pawła Kukiza jest większa czy mniejsza od nieufności do Roberta Biedronia. Gorzej wykres sugeruje, że nieufność do Biedronia jest większa niż do Kukiza, podczas gdy w rzeczywistości jest odwrotnie. Podobnie trudno jest określić dla konkretnego polityka czy zaufanie jest większe od nieufności albo o ile jest większe (lub mniejsze).. Można trochę poprawić wykres jeżeli wartości podzielimy na ujemne/dodatnie (wykres po prawej). Można ale po co? Najlepiej po prostu wykreślić oddzielne wykresy słupkowe dla każdej kategorii czyli wykreślić słupki z każdej kategorii oddzielniem na wspólnej linii zera: Wykres kołowy kolejny raz jest najmniej przydatny. Niemożliwe albo bardzo trudne jest zorientowanie się w różnicach odsetka zaufania/nieufności/nieznajmości dla poszczególnych kandydatów: Można spróbować połączyć wykres punktowy z wykresem słupkowym: Patrząc na słupki można ocenić nieznajomość; patrząc na kropki zaufanie/nieufność. W porówaniu do skumulowanego wykresu słupkowego zarówno łatwe jest porównanie poziomów każdego czynnika dla wszystkich ocenianych polityków, jak i porównanie dla konkretnego polityka (czy zaufanie jest większe od nieufności albo o ile jest większe/mniejsze). Ale uwaga jeżeli liczba wymiarów będzie większa niż trzy wykres straci na przejrzystości zamieniając się w chmurę różnokolorowych kropek. 2.4.9 Przykład: Marimekko mosaic chart Przykład: Kraje wg emisji C02 (wysokość prostokąta jest równa emisji per capita; szerokość liczbie ludności). Pola prostokątów odpowiadają globalnej emisji, wysokości emisji na głowę. Prostokąty są uszeregowane wg. emisji per capita, co utrudnia porówania wielkości globalnych. Ale i tak widać, że nie tylko Polska emituje mniej niż Niemcy ale przeciętny Niemiec emituje więcej niż przeciętny spalający na potęgę czarny węgiel Polak. 2.5 Analiza parametryczna 2.5.1 Miary położenia Miary przeciętne charakteryzują średni lub typowy poziom wartości cechy. Są to więc takie wartości, wokół których skupiają się wszystkie pozostałe wartości analizowanej cechy. Na rysunku po lewej mamy dwa rozkłady różniące się poziomem przeciętnym (czerwony ma przeciętnie mniejsze wartości niż turkusowy). Są to rozkłady jednomodalne, tj. wartości skupiają się wokół jednej wartości. Dla takich rozkładów ma sens obliczanie średnich. Na rysunku po prawej mamy rozkłady nietypowe: wielomodalne (turkusowy) lub niesymetryczne (wartości skupiają się nie centralnie ale po prawej/lewej od środka przedziału zmienności). W świecie rzeczywistym zdecydowana większość rozkładów jest jednomodalna. Klasyczne (średnia arytmetyczna) i pozycyjne (mediana, dominanta, kwartyle, kwantyle, decyle). Średnia artmetyczna (Mean, Arithmetic mean). Oblicznie średniej dla szeregu prostego (suma wartości podzielona przez liczbę składników sumy): \\[ \\bar x = \\frac{\\sum_{i=1}^N x_i} {N} \\] Mediana (Median, kwartyl drugi) dzieli zbiorowość na dwie równe części; połowa jednostek ma wartości cechy mniejsze lub równe medianie, a połowa wartości cechy równe lub większe od Me. Stąd też mediana bywa nazywana wartością środkową. Właśności mediany – odporna na wartości nietypowe (w przeciwieństwie do średniej) Przykład: współczynnik dzietności na świecie w roku 2018 Średnia wartość współczynnika 2.6778607; mediana – 2.2. Interpretacja średniej: wartość współczynnika dzietności wyniosła 2.6778607 dziecka. Uwaga: średnia dzietność na świecie nie wynosi 2.6778607 (bo kraje różnią się liczbą ludności). Interpretacja mediany: dzietność kobiet w połowie krajów na świecie wynosiło 2.2 i mniej. Uwaga: dzietność połowy kobiet na świecie wyniosła 2.2 i mniej jest niepoprawną interpretacją (różne wielkości krajów.) Generalna uwaga: interpretacja średniej-średnich często jest nieoczywista i należy uważać. (a współczynnik dzietości jest średnią: średnia liczba dzieci urodzonych przez kobietę w wieku rozrodczym. Jeżeli liczymy średnią dla 202 krajów, to mamy średnią-średnich). Inny przykład: odsetek ludności w wieku poprodukcyjnym wg powiatów (średnia z czegoś takiego nie da nam odsetka ludności w wieku poprodukcyjnym w Polsce, bo powiaty różnią się liczbą ludności.) Dominanta (Mode, Moda, wartość modalna, wartość najczęstsza) jest to wartość cechy statystycznej, która w szeregu empirycznym występuje najczęściej. W szeregach prostych i rozdzielczych jest to wartość cechy, której odpowiada największa liczebność (częstość). Kwartyle (Q, quartile, \\(Q_1\\), \\(Q_3\\)) – wartości cechy dla jednostek dzielących populację na cztery równe części. Kwartyl pierwszy dzieli populację w proporcji 25/75%, kwartyl drugi w proporcji 50/50%, a kwartyl trzeci w proporcji 75/25%. kwantyle (D, wartości dziesiętne), podobnie jak kwartyle, tyle że dzielą na 10 części. Centyle (P, wartości setne), podobnie jak kwantyle tyle że dzielą na 100 części. Przykładowo wartość 99 centyla i mniejszą ma 99% jednostek w populacji. 2.5.2 Miary zmienności Wariancja, odchylenie standardowe, odchylenie przeciętne, współczynnik zmienności (Pearsona) Wariancja (variance) jest to średnia arytmetyczna kwadratów odchyleń poszczególnych wartości cechy od średniej arytmetycznej zbiorowości. Oblicznie wariancji dla szeregu prostego: \\[ S^2 = \\frac{1}{N} \\sum_{i=1}^N (x_i - \\bar x)^2 \\] często zamiast dzielenie przez \\(N\\) dzielimy przez \\(N-1\\). Odchylenie standardowe (standard deviation, sd) jest pierwiastkiem kwadratowym z wariancji. Parametr ten określa przeciętne zróżnicowanie poszczególnych wartości cechy od średniej arytmetycznej. Współczynniki pozycyjne. Odchylenie ćwiartkowe (Q, midhinge): \\[ Q = \\frac{Q_3 - Q_1}{2} \\] i rozstęp ćwiartkowy (interquartile range, IQR): \\[ R_Q = Q_3 - Q_1 \\] Współczynnik zmienności jest ilorazem bezwzględnej miary zmienności cechy i średniej wartości tej cechy. W analizie struktury korzysta się z różnych miar położenia i zmienności, dlatego są współczynniki zmienności klasyczne i pozycyjne. Współczynniki klasyczne: \\[ V_s = \\frac{s}{\\bar x}\\qquad \\textrm{lub}\\qquad V_d = \\frac{d}{\\bar x} \\] pozycyjne \\[ V_Q = \\frac{Q_3 - Q_1}{\\textrm{Me}} \\] albo (Quartile coefficient of dispersion): \\[ V_Q = \\frac{Q_3 - Q_1}{Q_3 + Q_1} \\] Współczynnik zmienności jest wartością niemianowaną. Wartości liczbowe współczynników zmienności najczęściej są podawane w procentach. Przyjmuje się, że jeżeli współczynnik zmienności jest poniżej 10%, to cechy wykazują zróżnicowanie statystycznie nieistotne. Duże wartości tego współczynnika świadczą o dużym zróżnicowaniu, a więc niejednorodności zbiorowości. Współczynnik zmienności stosuje się zwykle w porównaniach, gdy chce się ocenić zróżnicowanie: kilku zbiorowości pod względem tej samej cechy, tej samej zbiorowości pod względem kilku różnych cech. UWAGA: ten współczynnik może dawać dziwne rezulataty jeżeli średnia wynosi zero (niezdefiniowany), jest ujemna lub jest bliska zera; zwłaszcza jeżeli użyjemy skali przedziałowej. Przykład: Średnie temperatury miesięczne. Sopot, Polska mc 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 Tm Sm Vm 01 -5.36 -0.41 -0.37 -1.77 -2.27 1.53 -2.39 -1.16 0.62 -0.31 -0.74 2.23 -299.54 02 -1.08 -3.19 -3.31 -0.13 2.55 1.44 2.72 -0.08 -2.56 3.27 -0.04 2.36 -6658.52 03 3.65 2.83 5.04 -0.87 6.09 4.91 4.09 5.04 -0.07 5.26 3.60 2.21 61.57 04 7.47 9.47 7.59 6.55 9.37 7.94 8.30 6.70 10.43 8.62 8.25 1.19 14.37 05 10.85 12.78 13.11 14.10 12.82 12.01 14.37 12.77 15.40 11.56 12.98 1.29 9.95 06 16.06 17.65 14.91 17.15 15.37 15.36 17.62 16.18 17.51 20.03 16.78 1.45 8.65 07 20.49 18.11 18.07 18.53 20.51 17.52 18.51 16.84 20.20 17.17 18.59 1.29 6.94 08 18.71 17.58 17.66 18.11 17.70 19.47 17.36 17.53 19.46 18.65 18.22 0.76 4.15 09 13.03 14.79 13.91 12.38 14.41 14.16 15.53 13.47 15.04 13.69 14.04 0.90 6.44 10 6.24 9.27 8.23 9.93 8.78 7.78 7.76 10.05 10.17 9.70 8.79 1.21 13.81 11 4.54 4.54 5.03 5.50 4.89 6.01 3.51 4.76 4.88 5.27 4.89 0.63 12.83 12 -5.03 3.00 -1.70 3.40 1.02 4.56 2.67 2.18 2.05 3.54 1.57 2.73 174.09 Tm -- średnia dla lat 2010-2019 Sm -- odchylenie standardowe dla lat 2010--2019 Vm -- współczynnik zmienności tj Vm = Sm / Tm * 100 Dla lutego współczynnik zmienności przymuje absurdalną wartość 6 tysięcy (procent). Do tego na minus. 2.5.3 Miary asymetrii Asymetria (skewness), to odwrotność symetrii. Szereg jest symetryczny jeżeli jednostki są rozłożone ,,równomiernie’’ wokół wartości średniej: \\[ \\bar x = \\textrm{Me} = D \\] Asymetria prawostronna, lewostronna; wskaźnik asymetrii (skośności), współczynniki asymetrii (skośności). Moment trzeci centralny – średnia arytmetyczna z podniesionych do potęgi trzeciej odchyleń wartości cechy od średniej arytmetycznej \\[ \\mu_3 = \\frac{1}{N} \\sum_{i=1}^N (x_i - \\bar x)^3 \\] jeżeli \\(\\mu_3 = 0\\) szereg symetryczny, \\(\\mu_3 &gt; 0\\) asymetria dodatnia (prawostronna), \\(\\mu_3 &lt; 0\\) asymetria ujemna (lewostronna) Moment trzeci względny określa siłę i kierunek asymetrii: \\[ g_1 = \\frac{\\mu_3}{s^3} \\] Na podstawie badań empirycznych: \\(-2 &lt; g_1 &lt; 2\\), w skrajnych przypadkach może przekraczać ten przedział. Współczynnik asymetrii (skośności) oparty na odległościach między średnimi (K. Pearson). \\[ W_s = \\frac{\\bar x - D}{s} \\] rzadziej używa się: \\[ W_s = \\frac{\\bar x - \\textrm{Me}}{s} \\] Współczynnik asymetrii (skośności) oparty na odległościach między kwartylami lub decylami: \\[ W_{sq} = \\frac{(Q_3 - Q_2) - (Q_2 - Q_1)}{Q_3 - Q_1} \\] 2.5.4 Miary koncentracji Koncentracja – nierównomierny podział wartości cechy w zbiorowości. Współczynnik Giniego i Krzywa Lorenza Krzywa Lorenza jest funkcją określoną na zbiorze liczb dodatnich L(Cn), gdzie Cn jest kumulowaną liczebnością zaś L kumulowaną wartość cechy. Zwykle wartości kumulowane są przedstawione w procentach co pozwala na zgrabną interpretację w stylu: 20% jednostek ma 5% łącznej wartości cechy albo 50% rolników posiada 15% łacznych areałów, itp. przekątna łącząca lewy-dolny, prawy-górny wierzchołek jest nazywana linią równomiernego rozkładu (koncentracji równomiernej, line of equality). Współczynnik Giniego to iloraz pola A do sumy pół A+B. Im większa koncentracji, tym krzywa Lorenza jest bardziej wygięta, a wartość współczynnika Ginego większa (maksymalną wartością jest 1) Współczynnik HH Innym współczynnikiem koncentracji jest współczynnik Herfindahla-Hirschmana (HH-Index, https://en.wikipedia.org/wiki/Herfindahl%E2%80%93Hirschman_Index): \\[HH = \\sum_{i=1}^N x_i^2, \\quad\\mathrm{gdzie}: \\sum_{i=1}^N x_i =100%\\] Maksymalną wartością tego współczynnika jest 10000, wartości większe od 1800 świadczą o znacznej koncentracji. "],["interference.html", "3 Łagodne wprowadzenie do wnioskowania statystycznego 3.1 Masa ciała uczestników PŚ w rugby 3.2 Wiek kandydatów na radnych 3.3 Rozkład normalny 3.4 Odsetek kobiet wśród kandydatów na radnych 3.5 Wnioskowanie statystyczne 3.6 Słownik terminów które warto znać", " 3 Łagodne wprowadzenie do wnioskowania statystycznego Chcemy się dowiedzieć czegoś na temat populacji (całości) na podstawie próby (części tej całości). Przykładowo chcemy ocenić ile wynosi średnia waga główki kapusty na 100 h polu. Można ściąć wszystkie i zważyć, ale można też ściąć trochę (pobrać próbę się mówi uczenie) zważyć i poznać średnią na całym polu z dobrą dokładnością. 3.1 Masa ciała uczestników PŚ w rugby W turnieju o Puchar Świata w rugby w 2015 roku uczestniczyło 623 rugbystów. Znamy szczegółowe dane odnośnie wzrostu i wagi każdego uczestnika turnieju. Obliczamy (prawdziwą) średnią, odchylenie standardowe i współczynnik zmienności masy ciała: ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 65.0 93.0 103.0 102.8 113.0 145.0 Czyli średnio rugbysta na turnieju RWC’2015 ważył 102.80 kg (Mean na wydruku powyżej) a odchylenie standardowe (s) wyniosło 12.92 kg. Rozkład, pokazany na rysunku 3.1, jest dwumodalny, bo w rugby są dwie grupy zawodników i wcale nie wszyscy ważą ponad 110 kilogramów. Rysunek 3.1: Rozkład wagi zawodników Szacujemy średnią na podstawie 2 zawodników pobranych losowo Powtarzamy eksperyment 1000 razy (dwóch bo dla jednego nie obliczymy wariancji) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 75.5 97.0 103.0 102.8 109.0 128.0 Średnia (średnich z próby) ma wartość 102.84 kilogramów a odchylenie standardowe 8.91 kilogramów. Wartość \\(s/\\sqrt{2}\\) (odchylenie standardowe podzielone przez pierwiastek kwadratowy z liczebności próby) jest równa 9.14. Zauważmy że ta wartość jest zbliżona do odchylenia standardowego uzyskanego w eksperymencie (8.91 vs 9.14). Zauważmy też że wartość najniższej średniej wyniosła 75.5 kilogramów zaś najwyższej 128 kilogramów. Gdybyśmy mieli pecha i wylosowali te skrajnie nieprawdziwe wartości to mylimy się o 27.34 kilogramów na minus lub 25.16 kilogramów na plus. szacujemy średnią na podstawie 10 zawodników pobranych losowo Powtarzamy eksperyment 1000 razy ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 89.7 99.9 102.8 102.7 105.6 115.6 średnia wyszła 102.67 kilogramów a odchylenie standardowe 4.23 kilogramów. Wartość \\(s/\\sqrt{10}\\) jest równa 4.09. szacujemy średnią na podstawie 40 zawodników pobranych losowo Uwaga: 40 zawodników to około 6.4% całego zbioru. Powtarzamy eksperyment 1000 razy ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 94.85 101.47 102.82 102.84 104.28 109.90 średnia jest równa 102.84 kilogramów a odchylenie standardowe 2.07 kilogramów. Wartość \\(s/\\sqrt{40}\\) jest równa 2.04. Zauważmy też że wartość najniższej średniej wyniosła 94.85 kilogramów zaś najwyższej 109.9 kilogramów. Gdybyśmy mieli pecha i wylosowali te skrajnie nieprawdziwe wartości to mylimy się o 7.99 kilogramów na minus lub 7.06 kilogramów na plus. Niewątpliwie wynik znacznie lepszy niż dla próby dwuelementowej. Podsumujmy eksperyment wykresem rozkładu wartości średnich (por. rysunek 3.2). Rysunek 3.2: Rozkład średniej wagi rugbystów w zależności od wielkości próby Wnioski z eksperymentu Wartość średnią wyznaczamy na podstawie jakiejś konkretnej metody. Wydaje się na podstawie powyższych eksperymentów, że z dobrym skutkiem możemy jako metodę wykorzystać średnią-z-próby. W ogólności taką metodą, która formalnie jest funkcją elementów z próby, nazywa się w statystyce estymatorem. Warto to pojęcie zapamiętać. Wnioskujemy o wartości nieznanego parametru w populacji posługując się estymatorem. Kontynuując wnioski z eksperymentu należy zauważyć, że wszystkie średnie-ze-średnich (bez względu na liczebność próby) są zbliżone do wartości prawdziwej (to się nazywa nieobciążoność estymatora); Mówiąc innymi słowy jeżeli będziemy oceniać wartość prawdziwej średniej na podstawie próby, a naszą ocenę powtórzymy wielokrotnie, to średnia będzie zbliżona do wartości prawdziwej (a nie np. niższa czy wyższa) Ta cecha jest niezależna od wielkości próby. Jeżeli rośnie liczebność próby to zmienność wartości średniej-w-próbie maleje, co za tym idzie prawdopodobieństwo, że wartość oceniona na podstawie średniej z próby będzie zbliżona do wartości szacowanego parametru rośnie (to się nazywa zgodność). Co więcej dobrym przybliżeniem zmienności średniej-w-próbie jest prosta formuła \\(s/\\sqrt{n}\\) gdzie \\(n\\) jest liczebnością próby a \\(s\\) jest odchyleniem standardowym w populacji z której pobrano próbę. Jeżeli mamy dwa różne estymatory służące do oszacowania parametru i oba są nieobciążone oraz zgodne, to który wybrać? Ten która ma mniejszą wariancję. Taki estymator nazywa się efektywny. Estymator zatem powinien być nieobciążony, zgodny oraz efektywny (czyli mieć małą wariancję). Można matematycznie udowodnić, że pewien estymator ma tak małą wariancję, że niemożliwe jest wynalezienie czegoś jeszcze bardziej efektywnego. Takim estymatorem średniej w populacji jest średnia z próby… Konkretną wartość estymatora dla konkretnych wartości próby nazywamy oceną (parametru). 3.2 Wiek kandydatów na radnych W wyborach samorządowych w Polsce w roku 2018 o mandat radnego sejmików wojewódzkich ubiegało się 7076 kandydatów. Znamy szczegółowe dane odnośnie wieku każdego kandydata, bo to zostało publicznie podane przez Państwową Komisję Wyborczą. Obliczamy (prawdziwą) średnią, odchylenie standardowe i współczynnik zmienności wieku kandydatów: ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 18.00 34.00 46.00 46.24 58.00 91.00 Czyli średnio kandydat miał 46.24 lat a odchylenie standardowe wieku wyniosło 14.61 lat. Rozkład znowu jest dwumodalny z jakiś powodów (por. rysunek 3.3). Rysunek 3.3: Rozkład wieku kandydatów na radnych Szacujemy średnią na podstawie 2 kandydatów pobranych losowo Powtarzamy eksperyment 1000 razy ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 20.00 39.50 46.50 46.13 53.00 75.00 Średnia średnich z próby ma wartość 46.13 lat. Odchylenie standardowe wyniosło 10.21. Wartość \\(s/\\sqrt{2}\\) jest równa 10.33. Wartość najniższej średniej wyniosła 20 lat zaś najwyższej 75 lat. Gdybyśmy mieli pecha i wylosowali te skrajnie nieprawdziwe wartości to mylimy się o 26.13 lat na minus lub 28.87 lat na plus. Szacujemy średnią na podstawie 10 kandydatów pobranych losowo Powtarzamy eksperyment 1000 razy. ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 31.00 42.90 46.25 46.26 49.52 61.80 Średnia średnich z próby ma wartość 46.26 lat. Odchylenie standardowe wyniosło 4.71. Wartość \\(s/\\sqrt{10}\\) jest równa 4.62. Szacujemy średnią na podstawie 40 kandydatów pobranych losowo Uwaga: 40 kandydatów to ok 0.6% całości. Powtarzamy eksperyment 1000 razy. ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 36.80 44.75 46.41 46.38 48.02 53.83 Średnia średnich z próby ma wartość 46.38 lat. Odchylenie standardowe wyniosło 2.35. Wartość \\(s/\\sqrt{40}\\) jest równa 2.31. Szacujemy średnią na podstawie 70 kandydatów pobranych losowo Uwaga: 70 kandydatów to około ok 1% całości (1000 powtórzeń) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 41.21 45.06 46.27 46.26 47.43 51.83 Średnia średnich z próby ma wartość 46.26 lat. Odchylenie standardowe wyniosło 1.75 Wartość \\(s/\\sqrt{70}\\) jest równa 1.75. Wartość najniższej średniej wyniosła 41.21 lat zaś najwyższej 51.83 lat. Gdybyśmy mieli pecha i wylosowali te skrajnie nieprawdziwe wartości to mylimy się już tylko o 5.05 lat na minus lub 5.56 lat na plus. Podsumujmy eksperyment wykresem rozkładu wartości średnich (rysunek 3.4). Rysunek 3.4: Rozkład średniej wieku kandydatów w zależności od wielkości próby Obserwujemy to samo co w przypadku wagi rugbystów: im większa próba tym dokładniejsza wartość średniej wieku. Bez względu na wielkość próby przeciętnie otrzymujemy prawdziwą wartość średniej. Wniosek: precyzja wnioskowania zwiększa się wraz z liczebnością próby; tym szybciej im rozproszenie w populacji generalnej jest mniejsze. Żeby z dużą dokładnością wnioskować o średniej dla dużej populacji wcale nie trzeba pobierać dużej próby (w ostatnim przykładzie było to 1% całości). 3.3 Rozkład normalny Rozkład empiryczny zmiennej to przyporządkowanie kolejnym wartościom zmiennej odpowiadających im liczebności. Załóżmy że istnieje zapotrzebowanie społeczne na wiedzę na temat wieku kandydatów na radnych. Możemy to jak widać łatwo liczyć ale jednocześnie jest to kłopotliwe. Należy do tego mieć zbiór ponad 7 tys liczb. Rozkład teoretyczny to matematyczne uogólnienie rozkładu empirycznego. Jest to model matematyczny operujący pojęciem (ściśle sformalizowanym) prawdopodobieństwa (zamiast liczebności). Rozkład teoretyczny jest: zbliżony do empirycznego jeżeli chodzi o wyniki (jest przybliżeniem empirycznego) jest zdefiniowany za pomocą kilku liczb; nie ma potrzeby korzystania z liczebności Żeby było ciekawiej istnieje dokładnie jeden rozkład teoretyczny, który z dobrą dokładnością opisuje rozkłady empiryczne będące wynikiem powyższej zabawy. Ten rozkład (zwany normalnym) zależy tylko od dwóch parametrów: średniej i odchylenia standardowego, gdzie średnia będzie równa (prawdziwej) średniej w populacji a odchylenie standardowe równe odchyleniu standardowemu w populacji podzielonemu przez pierwiastek z wielkości próby. Przybliżenie za pomocą rozkładu normalnego średniego rozkładu wieku kandydatów na radnych dla próby 40-elementowej oraz 70-elementowej pokazuje rysunek 3.5. Rysunek 3.5: Rozkład normalny Prawda, że wynik jest całkiem dobry? Teoretyczność czerwonej krzywej polega na tym, że ona zawsze będzie identyczna, podczas gdy histogram będzie różny. Gdybyśmy powtórzyli nasz eksperyment (generowania 1000 losowych prób przypominam), to zapewne trochę by się różnił, bo byśmy wylosowali inne wartości do prób. Ta teoretyczna abstrakcja nazywa się prawdopodobieństwem. Rzucając monetą 1000 razy spodziewamy się po 500 orłów i reszek, co w modelu matematycznym będzie opisane jak: prawdopodobieństwo wyrzucenia orła wynosi 0,5. Rzucanie monetą to bardzo prosty eksperyment; nasz z liczeniem średniej wieku jest bardziej skomplikowany więc miło jest się dowiedzieć, że używając czerwonej krzywej można łatwo obliczyć jak bardzo prawdopodobne jest na przykład popełnienie błędu większego niż 10% średniej, albo większego niż 0,1 lat. Albo jak duża powinna być próba żeby ten błąd był nie większy niż 0,1 lat. Interpretacja wartości rozkładu empirycznego zwykle jest w kategoriach ryzyka/szansy czy prawdopodobieństwa. Przykładowo interesuje nas prawdopodobieństwo, że kandydat ma mniej niż 30 lat. Takich kandydatów jest 1091 a wszystkich kandydatów dla przypomnienia jest 7076. Iloraz tych wartości będzie interpretowany jako ryzyko/szansa/prawdopodobieństwo (wynosi ono 15.42%.) Podobnie można obliczyć prawdopodobieństwo, że wiek kandydata będzie się zawierał w przedziale 50–60 lat. Ponieważ kandydatów w wieku 50–60 lat jest 1570, to szukane prawdopodobieństwo jest równe: 22.19%.) Jeżeli zamiast rozkładu empirycznego będziemy używać rozkład normalnego, który jak widzimy jest jego dobrym przybliżeniem, to nie musimy liczyć empirycznych liczebności. Wystarczy że znamy średnią i odchylenie standardowe a potrafimy obliczyć każde prawdopodobieństwo dla każdego przedziału wartości zmiennej. W szczególności dla rozkładu normalnego prawdopodobieństwo \\(m \\pm s\\) (przyjęcie wartości z przedziału średnia plus/minus odchylenie standardowe) wynosi około 0,68 prawdopodobieństwo \\(m \\pm 2 \\times s\\) wynosi około 0,95 a \\(m \\pm 3 \\times s\\) około 0,997. Czyli w przedziale \\([-3s &lt; m, m +3s]\\) znajdują się praktycznie wszystkie wartości rozkładu. Albo innymi słowy przyjęcie wartości spoza przedziału średnia plus/minus trzykrotność odchylenia standardowego jest bardzo mało prawdopodobna. Rozkład normalny będzie identyczny dla wagi rugbystów, wieku, wagi noworodków itd/itp. Uogólnieniem teoretycznym pojęcia zmiennej statystycznej, które do tej pory używaliśmy jest zmienna losowa, zmienna której wartości są liczbami a realizują się z określonym prawdopodobieństwem np. określonym przez rozkład normalny. 3.4 Odsetek kobiet wśród kandydatów na radnych Dane dotyczące kandydatów na radnych do sejmików wojewódzkich zawierają także płeć kandydata. Ktoś może być ciekaw jaki był odsetek kobiet w tej grupie. Taki parametr nazywa się proporcją albo ryzykiem, a potocznie i niefachowo procentem. Matematycznym modelem jest zmienna dwuwartościowa, która z określonym prawdopodobieństwem przyjmuje wartość kobieta. Obliczmy empiryczną wartość tego prawdopodobieństwa jako liczbę kobiet do liczby wszystkich kandydatów. Wartość tego parametru wynosi 0.4587 (albo 45.87%). Potraktujmy to jako prawdziwą wartość prawdopodobieństwa (p), że kandydat jest kobietą i empirycznie sprawdźmy czy możemy szacować o prawdziwej wartości tego parametru używając (jako estymatora żeby się przyzwyczajać do nowych terminów) proporcji z próby. Tradycyjnie powtarzamy eksperyment 1000 razy dla trzech różnych wielkości próby. Rozkład otrzymanych wartości przedstawia rysunek 3.6. Rysunek 3.6: Rozkład wielkości p dla różnej wielkości próby Wnioski: Dla próby 20 elementowej rozkład nie przypomina rozkładu normalnego. Dla prób 120 i 420 elementowej rozkład jest podobny do normalnego. Zmienność estymatora maleje wraz ze wzrostem liczebności próby; każe nam to przypuszczać (i tak jest w istocie) że jest on zgodny. W każdym przypadku średnia z 1000 eksperymentów jest zbliżona do wartości prawdziwej; każe nam to przypuszczać (i tak jest w istocie) że estymator jest nieobciążony. Rozkład normalny jest tak magiczny że nawet jeżeli zmienna, której parametr szacujemy nie ma rozkładu zbliżonego do normalnego (jak w przypadku zmiennej, która przyjmuje tylko dwie wartości) to i tak estymator tego parametru będzie normalny. Co najwyżej będziemy potrzebowali większej próby żeby „znormalniał” (jak w opisywanym przykładzie). 3.5 Wnioskowanie statystyczne Analizując dane uzyskane z próby celem jest ich uogólnienie na całą populację. To uogólnienie nazywa się wnioskowaniem (interferance). Przypominamy, że wnioskujemy o wartości parametru w populacji posługując się estymatorem. W przypadku wnioskowania o średniej estymatorem jest średnia-z-próby. Dobrze by było wiedzieć jak bardzo wiarygodna jest ta wartość (zwana oceną parametru) uzyskana na podstawie konkretnego estymatora, inaczej mówiąc jak dużo mogliśmy się pomylić. Do oceny tej wiarygodności można użyć wariancji-średniej-z-próby (która nazywa się wariancją błędu albo error variance). Jeżeli wariancja błędu jest duża, to w pojedynczej próbie mogą wystąpić wartości znacznie różniące się od prawdziwej średniej; jeżeli jest mała to takie bardzo różniące się od prawdziwej średniej wartości mają małe szanse na zaistnienie. Do tego w przypadku rozkładu normalnego wiemy ze wariancja błędu jest równa \\(s^2/n\\) (gdzie \\(s^2\\) jest wariancją w populacji a \\(n\\) wielkością próby.) W ramach wnioskowania stosowane są trzy metody (podejścia): estymacja punktowa, estymacja przedziałowa, testowanie hipotez. 3.5.1 Estymacja punktowa Szacujemy średnią (albo inny parametr) i tę wartość uznajemy za wartość prawdziwą; dokładność szacunku jest nieokreślona. Inaczej mówiąc wartość estymatora dla konkretnej próby przyjmujemy za ocenę parametru. Estymatorem punktowym średniej jest średnia z próby a estymatorem punktowym proporcji/ryzyka jest proporcja/ryzyko z próby. 3.5.2 Estymacja przedziałowa Nie można ustalić prawdopodobieństwa popełnienia błędu dla dokładnej wartości parametru (co wynika z właściwości matematycznych modelu), ale można dla dowolnego przedziału od–do. Czyli nie można ustalić, że z prawdopodobieństwem 95% oszacujemy wartość średnią czegoś jako 5,000000, ale można z prawdopodobieństwem 95% oszacować przedział, w którym znajdzie się średnia (przykładowo, że będzie to przedział 4,9–5,1). Estymacja przedziałowa to oszacowanie przedziału wartości od–do, który z zadanym z góry prawdopodobieństwem zawiera prawdziwą wartość parametru. Z góry wyznaczone prawdopodobieństwo nazywa się poziomem ufności (określa jak często mamy się NIE rąbnąć). 3.5.3 Testowanie hipotez Większość analiz statystycznych polega na porównaniu. W wyniku tego porównania otrzymujemy liczbę. Załóżmy, że mamy dwie próby dotyczące wieku kandydatów na radnych do sejmików wojewódzkich z roku 2018 (średnia 46,1) oraz z roku 2014 (47,2). Różnica wynosi 1,1 lat i może być spowodowana błędem przypadkowym (tj. gdybyśmy wylosowali jeszcze raz dwie próby, to wynik byłby zupełnie odmienny np 46,9 vs 46,5) i/lub wynikać z tego, że faktycznie w roku 2014 kandydaci byli starsi. Formalnie stawiamy hipotezę, że różnica średnich wynosi zero. Jest to tzw. hipoteza zerowa. Niezbędne jest także postawienie hipotezy alternatywnej, którą może być proste zaprzeczenie zerowej. Zapisuje się to następująco (\\(m_{14}\\)/\\(m_{18}\\) oznacza odpowiednio średnie w latach 2014/2018): \\(H_0\\): różnica średnich wieku wynosi zero (\\(m_{14} = m_{18}\\)) \\(H_1\\): różnica średnich wieku jest różna od zera (\\(m_{14} \\not= m_{18}\\)) Hipotezy sprawdzamy wykorzystując test statystyczny czyli zmienną losową której rozkład prawdopodobieństwa zależy (jest funkcją powiedziałby matematyk) od wartości testowanych parametrów (w tym przypadku \\(m_{14}\\) oraz \\(m_{18}\\)). Tę zmienną losową nazywa się statystyką testu. Nie jest chyba wielkim zaskoczeniem, że statystyką testu w teście różnicy średnich jest różnica średnich w próbie (poprawnie mówiąc różnica uwzględniająca liczebność próby oraz zmienność obu populacji). Całkiem zdroworozsądkowo możemy przyjąć, że duże różnice statystyki testu świadczą na rzecz hipotezy alternatywnej, natomiast małe na rzecz hipotezy zerowej. Duża różnica pomiędzy hipotezą a wynikiem z próby może wynikać z tego, że Pechowo trafiła nam się nietypowa próba, który zdarza się rzadko (rozkład normalny). Hipoteza jest fałszywa, średnie mają inną wartość niż zakładamy w hipotezie zerowej. Statystyk zawsze wybierze drugą wersję. Pozostaje tylko ustalić (dla statystyka) co to jest rzadko? Rzadko to z prawdopodobieństwem mniejszym niż z góry ustalone prawdopodobieństwo otrzymania różnicy (zakładając, że hipoteza zerowa jest prawdziwa), którą otrzymaliśmy w próbie lub większej (coś jak założenie, że zrealizował się najlepszy z najgorszych scenariuszy). Przyjmijmy przykładowo, że prawdopodobieństwo wystąpienia różnicy 1,1 lat (i większej) oszacowane na podstawie odpowiedniego modelu matematycznego (rozkład normalny) wynosi 0,3 co znaczy że coś takiego zdarza się względnie często – trzy razy na 10 pobranych prób. Załóżmy z kolei że, ta różnica wyniosła 3,2 lata. Prawdopodobieństwo wystąpienia takiej różnicy (i większej) wynosi 0,009 co znaczy że coś takiego zdarza się względnie rzadko – 9 razy na tysiąc prób. Przyjmując, że możemy się mylić 5 razy na 100 w pierwszym przypadku statystyk powie, że nie ma podstaw do odrzucenia hipotezy \\(H_0\\). Różnica 1,1 lat wynika z przypadku. W drugim wypadku statystyk powie, że hipoteza jest fałszywa, bo zdarzyło się coś co nie powinno się zdarzyć. Prawdopodobieństwo „graniczne” ustalamy z góry i nazywa się ono poziomem istotności. Określa ono jak często możemy się rąbnąć odrzucając hipotezę zerową, która jest prawdziwa. Ale jest jeszcze drugi przypadek popełnienia błędu: przyjmujemy hipotezę zerową, która jest fałszywa. W testach statystycznych nie określa się prawdopodobieństwa popełnienia tego błędu, a w związku z tym nie można przyjąć hipotezy zerowej (bo nie znamy ryzyka popełnienia błędu). W konsekwencji hipotezę zerową albo się odrzuca albo nie ma podstaw do odrzucenia. Wniosek cokolwiek niekonkluzywny, ale tak jest. Dlatego też często „opłaca się” tak postawić hipotezę zerową aby ją następnie odrzucić, bo taki rezultat jest bardziej konkretny. 3.5.4 Testy nieparametryczne Można testować hipotezy na temat wartości parametrów, ale można też testować przypuszczenia o charakterze mniej konkretnym. Na przykład, że dwie zmienne są niezależne (co to znaczy wyjaśniono w następnym rozdziale), albo że dwa rozkłady są podobne do siebie (rozkłady nie średnie). Takie hipotezy/testy określa się jako nieparametryczne. Przykładami są testy niezależności chi-kwadrat albo normalności Shapiro-Wilka (opisane w następnym rozdziale) Oczywiste, ale powtórzmy: przypuszczenia o charakterze nieparametrycznym możemy tylko testować (sprawdzać hipotezy); nie obliczamy wtedy ani ocen ani nie wyznaczamy przedziałów ufności. 3.6 Słownik terminów które warto znać Estymacja (punktowa, przedziałowa): szacowanie wartości parametru na podstawie próby. Estymator (nieobciążony, zgodny, efektywny): funkcja na wartościach próby która służy do oszacowania parametru. Hipoteza statystyczna: przypuszczenie dotyczące parametru lub rozkładu zmiennej. Ocena (parametru): konkretna wartość estymatora dla pewnej próby. Poziom istotności (testu; oznaczany jako \\(\\alpha\\); zwykle 0,05): prawdopodobieństwo popełnienia błędu. Poziom ufności = prawdopodobieństwo, że przedział ufności zawiera prawdziwą wartość parametru; oznaczany jako \\(1- \\alpha\\); zwykle 0,95. Rozkład (prawdopodobieństwa): przypisanie prawdopodobieństwa wartościom zmiennej losowej. Test statystyczny: metoda weryfikacji hipotezy statystycznej. Wnioskowanie statystyczne: wnioskowanie o całości na podstawie próby. "],["analiza-korelacji.html", "4 Analiza korelacji 4.1 Pojęcia wstępne 4.2 Pomiar siły zależności: regresja liniowa", " 4 Analiza korelacji 4.1 Pojęcia wstępne Pomiędzy zjawiskami występują związki (zależności.) Nauki formułują te związki w postaci praw. Jak takie prawo naukowe powstaje? Typowo w dwu etapach, najpierw za pomocą dedukcji stawia się hipotezę, potem konfrontuje się hipotezę z danymi (podejście hipotetyczno-dedukcyjne). Na tym drugim etapie używa się statystyki (lub matematyki jeżeli prawo ma charakter deterministyczny) Upraszczając metoda hypodedukcji sprowadza się do dedukcyjnego sformułowania hipotezy, która następnie jest empirycznie falsyfikowana, tj. próbuje się wykazać, że jest ona nieprawdziwa. Konsekwencje: nie można dowieść prawdziwości żadnej hipotezy, można natomiast wykazać, że hipoteza jest fałszywa. Związki między cechami mogą być: funkcyjne (nauki przyrodnicze) – wartościom jednej zmiennej odpowiada tylko jedna wartość drugiej zmiennej lub stochastyczne – wartościom jednej zmiennej odpowiadają z pewnym przybliżeniem wartości innej zmiennej. Problem: czy istnieje związek (zależność) pomiędzy cechami? Jaki jest charakter zależności? Jaka jest siła zależności? Przykładowo czy istnieje związek pomiędzy wielkością dochodu (przyczyna) a wielkością spożycia mięsa (skutek), albo jako jest zależność pomiędzy wielkością produkcji, nakładami kapitałowymi i wielkości nakładów pracy? 4.1.1 Korelacyjny wykres rozrzutu (korelogram, wykres XY w Excelu, scatter plot) W układzie kartezjańskim każdej obserwacji odpowiada kropka o współrzędnych XY. O występowaniu związku świadczy układanie się kropek według jakiegoś kształtu (krzywej). O braku związku świadczy chmura punktów niepodobna do żadnej krzywej. Punkty układające się według prostej świadczą o zależności liniowej (wyjątek: linia pozioma lub pionowa) Punkty układające się według krzywej świadczą o zależności nieliniowej. Przykład: Zależność pomiędzy zamożnością a spożyciem mięsa Organizacja Narodów Zjednoczonych do spraw Wyżywienia i Rolnictwa znana jako FAO udostępnia dane dotyczące konsumpcji żywności na świecie. Bank światowy udostępnia dane dotyczące dochodu narodowego. Konsumpcja mięsa jest mierzona jako średnia konsumpcja w kilogramach w każdym kraju (per capita się mówi); Dochód podobnie jako średnia wielkość dochodu narodowego per capita. Dane dotyczą roku 2013. 4.1.2 Pomiar siły zależności: współczynnik korelacji liniowej Pearsona Kowariancja to średnia arytemtyczna iloczynów odchyleń wartości zmiennych \\(X\\), \\(Y\\) od ich wartości średnich. Dla \\(n\\) obserwacji na zmiennych \\(X\\) oraz \\(Y\\) można powyższe zapisać w postaci następującej formuły: \\[\\mathrm{cov} (xy) = \\frac{1}{n} \\left( (x_1 - \\bar x) (y_1 - \\bar y) + ... + (x_n- \\bar x) (y_n - \\bar y) \\right)\\] Kowariancja zależy od rozproszenia (im większe tym większa), ma też dziwną jednostkę (jednostkaX · jednostkaY) oraz zależy od wybranych skal (tony vs gramy na przykład.) Z powyższych powodów do pomiaru związku pomiędzy cechami używa się standaryzowanego współczynnika kowariancji, zwanego współczynnikiem korelacji liniowej, (Pearson linear correlation coefficient). Standaryzacja polega na podzieleniu wartości kowariacji przez iloczyn odchyleń standardowych \\(s_x\\) oraz \\(s_y\\). \\[r_{xy} = \\frac{\\mathrm{cov}(xy) }{s_x \\cdot s_y}\\] Współczynnik jest miarą niemianowaną, przyjmującą wartości ze zbioru \\([-1;1]\\); Skrajne wartości \\(\\pm 1\\) świadczą o związku funkcyjnym (wszystkie punkty układają się na linii prostej); wartość zero świadczy o braku związku (linia pozioma/pionowa) Interpretacja opisowa: wartości powyżej 0,9 świadczą o silnej zależności. Przykład: korelacja między spożyciem mięsa a GDP Współczynnik korelacji liniowej wynosi 0.6823158 (umiarkowana korelacja). Czy ta wartość jest istotnie różna od zera? Jest na to stosowny test statystyczny, który sprowadza się do określenia jakie jest prawdopodobieństwo otrzymania r = 0.6823158 przy założeniu że prawdziwa wartość r wynosi zero. Otóż w naszym przykładzie to prawdopodobieństwo wynosi 3.850676e-26 (czyli jest ekstremalnie małe – r jest istotnie różne od zera). 4.1.3 Macierz korelacji Wstępnym etapem analizy zależności między zmiennymi jest często hurtowa ocena współczynników korelacji w postaci kwadratowej macierzy korelacji. Przykład: korelacja pomiędzy wiekiem, edukacją, szczęściem a stanem zdrowia Mohammadi S. i inni badali zależność pomiędzy wiekiem, poziomem edukacji, szczęściem a stanem zdrowia. (The relationship between happiness and self-rated health: A population-based study of 19499 Iranian adults; https://doi.org/10.1371/journal.pone.0265914) ## age edu Happiness Health ## age 1.00000000 -0.18341325501 0.04491863 0.00125622963 ## edu -0.18341326 1.00000000000 0.07418519 -0.00003728405 ## Happiness 0.04491863 0.07418519038 1.00000000 0.17863069296 ## Health 0.00125623 -0.00003728405 0.17863069 1.00000000000 Albo w bardziej efektownej postaci tekstowo-graficznej: 4.2 Pomiar siły zależności: regresja liniowa "],["analiza-szeregów-czasowych.html", "5 Analiza szeregów czasowych 5.1 Pojęcia wstępne 5.2 Wykresy 5.3 Przyrosty 5.4 Indeksy agregatowe 5.5 Dekompozycja szeregów czasowych 5.6 Wygładzanie za pomocą średniej ruchomej 5.7 Liniowa funkcja trendu 5.8 Wygładzanie wykładnicze 5.9 Oszacowanie dokładności modelu 5.10 Szacowanie wskaźników sezonowości", " 5 Analiza szeregów czasowych 5.1 Pojęcia wstępne Szereg czasowy to ciąg pomiarów z kolejnych momentów/okresów czasu. Szereg czasowy jest szeregiem okresów jeżeli dotyczy strumieni (zasobów). Przykładowo liczba urodzeń żywych w powiecie kwidzyńskim w latach 2010–2019, to szereg okresów. W szczególności można dodać liczbę urodzeń w poszczególnych latach otrzymując łączną liczbę urodzonych w tym okresie. Urodzenia żywe w powiecie kwidzyńskim w latach 2010--2019 2010 | 2011 | 2012 | 2013 | 2014 | 2015 | 2016 | 2017 | 2018 | 2019 ------+------+------+------+------+------+------+------+------+------ 965 | 937 | 907 | 821 | 831 | 785 | 813 | 861 | 834 | 833 Źródło: https://bdl.stat.gov.pl/ W latach 2010–2019 w powiecie kwidzyńskim urodziło się 965 + 937 + … + 833 = 8587 dzieci (średnio 858,7 rocznie). Albo szereg czasowy jest szeregiem momentów jeżeli dotyczy stanów. Przykładowo liczba ludności powiatu kwidzyńskiego w latach 2010–2019 (stan na 31.12), to szereg czasowy momentów. Ludność ogółem w powiecie kwidzyńskim w latach 2010--2019 2010 | 2011 | 2012 | 2013 | 2014 | 2015 | 2016 | 2017 | 2018 | 2019 ------+------+-------+------+------+------+------+------+------+------ 83562 |83734 | 83783 |83611 |83627 |83464 |83495 |83423 |83291 | 83174 Źródło: https://bdl.stat.gov.pl/ (Zwróćmy uwagę że taki szereg zwykle w tytule ma magiczną formułę stan na dzień-miesiąc – w przykładzie stan na ostatni dzień roku) Nie można sumować liczby mieszkańców z kolejnych lat, bo taka suma nie ma merytorycznie sensu. Można podać średnią (przeciętny stan) ludności jako wartość średniej chronologicznej: \\[\\bar x_{ch} = (\\frac{1}{2} x_1 + x_2 + ... + x_{n-1} + \\frac{1}{2} x_{n} ) / (n-1) = (83562/2 + 83734 + ... + 83291 + 83174/2)/9 = 83532,9\\] Średnia roczna liczba ludności w powiecie kwidzyńskim w latach 2010–2019 wyniosła zatem 83532,9 mieszkańców. Szeregi czasowe mogą różnić się częstotliwością (dzienna, tygodniowa, miesięczna, kwartalna, roczna). 5.2 Wykresy W przypadku szeregów czasowych celem wizualizacji jest: pokazanie poziomu zjawiska, jego dynamiki (spada, rośnie, zmienia się cyklicznie), porównanie poziomów/dynamiki wielu zmiennych. Do wizualizacji szeregów czasowych należy stosować wykresy liniowe, słupkowe lub punktowe, 5.2.1 Przykład: Zwiedzający Muzeum Zamkowe w Malborku Liczbę zwiedzających Muzeum Zamkowe w Malborku w latach 2015–2019 (dane miesięczne) przedstawiono na wykresach Wykres kropkowy zwykle się nie sprawdza. Jeżeli przebieg zjawiska nie jest uporządkowany, albo wykres zawiera kilka zmiennych (w przykładzie dwie zmienne). to wynikiem jest chmura różnokolowych kropek, w której trudno się połapać. Wykres liniowy zwykle daje najlepsze rezultaty. Wykres słupkowy z półprzeźroczystymi słupkami też zwykle się nie sprawdza (w przykładzie jeden słupek zawsze zachodzi na drugi, co w rezultacie prowadzi do sytuacji, że turkusowego koloru w ogóle nie ma na wykresie) Wykres słupkowy ze słupkami przylegającymi do siebie (grupowany) jest dobrą alternatywą dla wykresu liniowego. 5.3 Przyrosty Oznaczmy wartość zmiennej \\(Y\\) w okresie \\(t\\) jako \\(y_t\\) (mówi się okres badany) oraz wartość zmiennej \\(Y\\) w okresie \\(0\\) jako \\(y_0\\) (okres podstawowy). Przyrost absolutny to po prostu \\(y_t - y_0\\). Jeżeli obliczamy przyrosty dla wielu okresów, to można porównywać zawsze do jednego okresu/momentu: \\[y_2 - y_1, y_3 - y_1, \\ldots, y_{n-1} - y_1, y_{n} - y_1\\] lub dla poprzedniego okresu/momentu \\[y_2 - y_1, y_3 - y_2, \\ldots, y_{n-1} - y_{n-2}, y_{n} - y_{n-1}\\] W pierwszym przypadku mówimy o przyrostach jednopodstawowych, w drugim zaś o przyrostach łańcuchowych. Zwróćmy uwagę, że podstawa nie musi być równa pierwszej wartości. Może to być np. wartość ostatnia lub środkowa: \\[y_1 - y_n, y_2 - y_n, \\ldots, y_{n-2} - y_n, y_{n-1} - y_n\\] Interpretacja: o ile wzrosła/spadła wielkość zjawiska w okresie badanym w porównaniu do podstawowego w jednostkach zmiennej \\(Y\\) oczywiście. Przyrost względny to \\((y_t - y_0)/y_0\\) Jeżeli obliczamy przyrosty dla wielu okresów, to podobnie jak przyrosty absolutne możemy się posługiwać indeksami jednopodstawowymi lub łańcuchowymi. Przyrost względny zwykle wyrażone są w procentach jeżeli \\(y_t = 115\\) a \\(y_0 = 100\\), to $(y_t - y_0)/y_0 =115 $. Zjawisko ma o 15% wyższy poziom w roku \\(t\\). Wskaźniki dynamiki (indeksy): określają względną zmianę wartości szeregów czasowych (popularny procent zmiany), czyli \\(y_t/y_0\\). Jeżeli podstawą porównań jest okres poprzedni \\(y_t/y_{t-1}\\) to indeks nazywany jest łańcuchowym, jeżeli podstawa porównań jest stała, tj. \\(y_t/y_{c}\\), to indeks nazywany jest jednopodstawowy. Indeks zwykle wyrażone są w procentach jeżeli \\(y_t = 115\\) a \\(y_0 = 100\\), to $y_t/y_0 =15 $. Zjawisko ma o 15% wyższy poziom w roku \\(t\\). Używamy średniej geometrycznej do obliczenia średniego tempa zmian zjawiska w czasie: \\[\\bar y_g = \\sqrt[n-1]{y_n/y_1}\\] Przykład: Zwiedzający Muzeum Zamkowe w Malborku 5.4 Indeksy agregatowe Jeżeli celem jest porównanie wielu różnych dóbr należy znaleść wspólny mianownik, którym jest zwykle cena albo koszty. Załóżmy że jest to cena. Dysponujemy informacją na temat wielkości sprzedaży pewnej grupy \\(i\\) dóbr w okresie \\(1\\), tj. \\(q_{1i}\\) oraz w okresie \\(0\\), tj. \\(q_{0i}\\). Dysponujemy także informacją na temat cen tych \\(i\\) dóbr w okresie \\(1\\), tj. \\(p_{1i}\\) oraz w okresie \\(0\\), tj. \\(p_{0i}\\). Agregatowy indeks wartości jest definiowany jako: $$I_w = Indeks ten określa jak widać zmianę względną wartości grupy towarów w okresie \\(1\\) w porówaniu do okresu \\(0\\). Można też szacować wpływ zmiany cen i ilości towarów oddzielnie stosując następujące formuły agregatowy indeks ilości Laspeyresa: \\(I^L_q = \\frac{\\sum_i q_{1i} p_{0i}}{ \\sum_i q_{0i} p_{0i}}\\) agregatowy indeks ceny Laspeyresa: \\(I^L_p = \\frac{\\sum_i q_{0i} p_{1i}}{ \\sum_i q_{0i} p_{0i}}\\) agregatowy indeks ilości Paaschego: \\(I^P_q = \\frac{\\sum_i q_{1i} p_{1i}}{ \\sum_i q_{0i} p_{1i}}\\) agregatowy indeks ceny Paaschego: \\(I^P_p = \\frac{\\sum_i q_{1i} p_{1i}}{ \\sum_i q_{0i} p_{1i}}\\) Interpretacja: przy przyjęciu poziomu cen z okresu \\(x\\) ceny/ilości zmieniły się o \\(y\\) procent. Co jest \\(x\\)em zależy od przyjętej formuły standaryzacyjnej. 5.5 Dekompozycja szeregów czasowych Najczęściej stosowanym modelem szeregu czasowego dla zjawisk ekonomiczno-społecznych jest traktowanie go jako sumy (lub iloczynu) trzech składników: ogólnej, wieloletniej tendencji cyklicznych wahań okresowych oraz czynników pozostałych: \\[Y_t = T_t + S_t + e_t\\] Ogólna, wieloletnia tendencja zwana jest trendem, zaś cyklicznych wahań okresowych potocznie określane są jako sezonowość. Sezonowość jest typowym atrybutem wielu kategorii ekonomicznych i wynika ze zmienności warunków przyrodniczych czy też systemu społeczno-prawnego (okres urlopowy, koniec roku finansowego itd.) Metody wyodrębniania tendencji rozwojowej (trendu): średnia ruchoma, liniowa funkcja trendu, wygładzanie wykładnicze. Sezonowość a ocena kierunku/wielkości zmiany wartości szeregu czasowego: wyciąganie wniosków na podstawie wyłącznie porównywania obserwacji w kolejnych okresach w szeregu czasowym cechującym się sezonowością jest albo przejawem niewiedzy albo manipulacji (zwykle motywowanej politycznie). Na przykład wiadomo, że wielkość zatrudnienia wykazuje wahania sezonowe, bo w zimie zapotrzebowanie na pracowników spada. Stąd na przykład zatrudnienie w pierwszym kwartale (prawie) zawsze będzie niższe niż w czwartym kwartale roku poprzedniego. Jeżeli ktoś sprzedaje ten fakt jako argument, że rząd sobie nie radzi z gospodarką, to mamy do czynienia z manipulacją. Należy w takiej sytuacji porównywać rok-do-roku (czyli kwartał-do-kwartału dla danych kwartalnych), lub porównywać dane odsezonowane, czyli takie, które zostały poddane transformacji usuwającej efekt wahań sezonowych. Nb. odsezonowanie zawsze pozostawia pole do manipulacji w postaci konkretnej metody odsezonowania. Dlatego osobiście wolę porównywać dane z okresów jednoimiennych (porównanie rok-do-roku) co i państwu radzę:-) 5.6 Wygładzanie za pomocą średniej ruchomej Koncepcyjnie bardzo prosta metoda: obliczamy średnią dla kolejnych \\(k\\) wartości szeregu czasowego. Obliczone wartości zastępują wartości oryginalne. Wartości średniej ruchomej \\(k\\)-elementowej są obliczane jako: \\[\\bar y_p = (x_p + x_{p+1} + x_{p+2})/3, \\textrm{gdzie: } p=1,\\dots, N-2\\] Rezultatem jest szereg skrócony dokładnie o \\(N-2\\) elementów, gdzie \\(N\\) jest liczbą elementów szeregu oryginalnego. Jest też problem z określeniem okresu, którego dotyczą obliczone wartości. Czy \\(\\bar y_1\\) to obserwacja dla pierwszego, drugiego czy trzeciego okresu? W zasadzie każdy wariant będzie OK, zwykle wybiera się element środkowy. Dla danych miesięcznych i \\(k=12\\) szereg wygładzony będzie krótszy o 11 obserwacji i nie ma elementu środkowego (są dwa środkowe: czerwiec i lipiec). Można kompliować metodę i liczyć średnią ze środkowych albo zdecydować się na przypisanie średniej wartości do czerwca albo do lipca. Takie to są uroki średniej ruchomej… 5.7 Liniowa funkcja trendu Metoda zakładająca, że trend ma postać funkcji liniowej postaci \\(Y=b1\\dot t +b0\\). Parametry tej funkcji są obliczane metodą najmniejszych kwadratów, w której minimalizuje się sumę kwadratów odchyleń wartości empirycznych (observed values) od wartości teoretycznych (predicted values), tj. $_i^N y - y $, gdzie \\(\\hat y\\) to wartości teoretyczne czyli \\(\\hat y = b1 \\cdot t + b0\\), zaś \\(t=1,...N\\). Różnica \\(y - \\hat y\\) to błąd (error). Ideę metody NK zwanej jest w języku angielskim Least Squares przedstawia rysunek (zamiast \\(t\\) jest tam \\(x\\)). Wartość \\(b1\\) ma interesującą interpretację, a mianowicie jest to przeciętna zmiana \\(Y\\) z okresu na okres. 5.8 Wygładzanie wykładnicze Oryginalne obserwacje są zastępowane obserwacjami obliczonymi według \\(S_t = α y_{t-1} + (1 – α) S_{t-1}\\), gdzie \\(a \\in (0,1)\\) im \\(\\alpha\\) bliższe jedności tym krzywa trendu będąca wynikiem wgładzenia jest bardziej gładka. 5.9 Oszacowanie dokładności modelu Zastąpienie wartości oryginalnych (empirycznych) obliczonymi (teoretycznymi) prowadzi do błędu \\(\\hat y_t - y_t = e_t\\). Błąd średniokwadratowy (MSE) definiowany jako \\(\\sum_i^N (\\hat y-y)^2\\) to jak widać suma kwadratów różnic między wartościami teoretycznymi a oryginalnymi (empirycznymi). Im MSE jest większe tym model teoretyczny mniej dokładnie opisuje dane empiryczne. Jest to miara mianowana a mianem jest kwadrat jedostki miary \\(Y\\). Czyli jeżeli na przykład \\(Y\\) jest liczbą zwiedzających, to MSE będzie kwadratem liczby zwiedzających. Dość abstrakcyjne pojęcie, zatem do celów interpretacji oblicza się zwykle RMSE, pierwiastek błędu średniokwadratowego. RMSE ma już normalną interpretację: wartości teoretyczne średnio różnią się od rzeczywistych wartości zmiennych o wartość współczynnika RMSE. Względną miarą dokładności może być następujący wariant współczynnika zmienności: \\(V_\\mathrm{RMSE} = \\frac{\\mathrm{RMSE}}{\\bar y }\\cdot 100\\). Interpretacja: średnio błąd stanowi \\(V_\\mathrm{RMSE}\\) procent wartości średniej zmiennej \\(Y\\). 5.10 Szacowanie wskaźników sezonowości Najprostszą metodą oszacowania sezonowości jest obliczenie średnich dla okresów jednoimiennych, tj dla danych kwartalnych będą to średnie dla poszczególnych kwartałów a dla danych miesięcznych dla miesięcy. Następnie obliczamy wskaźniki sezonowości według formuły: \\(S_k = \\bar y_k / \\bar y\\), gdzie \\(\\bar y_k\\) średnia dla okresu \\(k\\), \\(\\bar y\\) średnia wartość szeregu czasowego (wszystkie obserwacje). Dla celów interpretacji zwykle mnoży się \\(S_k\\) przez \\(100\\), co pozwala na stwierdzenia w rodzaju przeciętnie w pierwszym kwartale wartości Y są wyższe o 12% od wartości trendu Obliczone wartości mogą służyć do poprawienia dokładności modelu zamiast \\(\\hat y=at +b\\) obliczamy \\(\\hat y=(at+B)*S_k\\). Przykład: Zwiedzający Muzeum Zamkowe w Malborku Wyznaczania trendu z wykorzystaniem średniej ruchomej, trendu liniowego, wygładzania wykładniczego za pomocą arkusza LibreOffice (który polecam) służą funkcje dostępne w menu Dane-Statystyka (a dalej al oraz oszacowania wskaźników sezonowości można "],["literatura.html", "6 Literatura", " 6 Literatura Sobczak Mieczysław, Statystyka, PWN 2024 (jeden z wielu podręczników do statystyki dla ekonomistów; starsze wydania do nabycia na Allegro za kilka-kilkanaście PLN): "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
