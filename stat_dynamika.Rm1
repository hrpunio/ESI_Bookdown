---
title: 'Statystyka: analiza dynamiki zjawisk'
author:
- name: Tomasz Przechlewski
  email: t.plata-przechlewski@psw.kwidzyn.edu.pl
  affiliation: Powiślańska Szkoła Wyższa (Kwidzyn/Poland)
date: "Jan. 2023"
output:
  html_document:
    includes:
      before_body: misc_hdr.html
description: (c) Tomasz Przechlewski / CC-BY license
resource_files:
- covariance_explained.png
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

every_nth = function(n) {
  return(function(x) {x[c(TRUE, rep(FALSE, n - 1))]})
}
```

## Pojęcia i definicje

Szereg czasowy (**time series**),
to ciąg wartości w kolejnych jednostkach czasu. Co oznacza, że nie jest to
zbiór tylko właśnie ciąg (tj. zbiór uporządkowany)

Szereg czasowy: momentów/okresów. Szeregi momentów rejestrują pewien **stan**
(liczba chorych w szpitalu na ostatni dzień miesiąca)
szeregi czasowe rejestrują pewien zasób (liczba przyjętych do szpitala w miesiącu).

Częstotliwość szeregu czasowego: dzienna, tygodniowa, miesięczna, kwartalna, roczna.
Mogą być dane rejestrowane jeszcze częściej: godzinowe albo nawet minutowe.

## Analiza

**Porównanie dynamiki** (najprostsza analiza): kiedy rośnie/kiedy spada. Jak rośnie/jak spada (szybciej/wolniej/cyklicznie itd.) 
Należy zwrócić uwagę na: 1) porównujemy to samo
(w długim okresie czasu zjawisko może być różnie definiowane/mierzone);
2) porównujemy jednakowe przedziały czasowe (realnie nie formalnie -- luty/marzec to różnica 10% z definicji jeżeli chodzi o liczbę dni); 
3) uwzględniamy **naturalne cykle**
dynamiki zjawiska (lato/jesień; grudzień/styczeń; wakacje itd)

**Poziom przeciętny** średnia (szereg czasowy okresów); średnia chronologiczna
(szereg czasowy momentów.) Średnia chronologiczna jest liczona jak normalna średnia
z tą różnicą, że pierwszy/ostatni element średniej jest dzielony przez 2 (czyli dodajemy pół pierwszego/ostatniego elementu a nie cały) oraz że nie dzielimy przez 
$N$ tylko przez $N-1$.

**Przyrosty absolutne** ($P_a$): różnica między poziomem zjawiska w okresie badanym
do okresu podstawowego (bazowego); $P_a = P_t - P_0$ gdzie $P_t$ oznacza
wielkość w okresie badanym a $P_0$ wielkość w okresie podstawowym.
Np. liczba pacjentów na oddziala wzrosła w grudniu w porównaniu
do listopada 40 (albo spadła o 31)

Można liczyć $P_a$ biorąc za podstawę wybrany okres/moment -- takie $P_a$ nazywa się
jednopodstawowe (*fixed base*); lub biorąc za podstawę poprzedni okres/moment -- łańcuchowe (*chain*).

**Przyrosty względne** ($P_w$) : 
względna różnica czyli iloraz $P_a$ do poziomu w okresie
podstawowym, zwykle w procentach; $P_w = (P_t - P_0)/P_0$.
Liczba pacjentów wzrosła 15% w porównaniu do okresu podstawowego.


Mogą być łańcuchowe jak jednopodstawowe.

**Wskaźniki dynamiki** ($W_d$) zwane też **indeksami**:względna miara 
dynamiki -- iloraz poziomu zjawiska
w okresie badanym do poziomu w okresie podstawowym, zwykle w procentach;
$W_d = P_t/P_0$
Zachodzi zależność: $W_d = 100 + P_w$.

Interpretacja (oczywista): odejmujemy od wartości $W_d$ 100%. Jeżeli
wartość jest mniejsza od zera interpretujemy jako spadek.

Np. liczba pacjentów na oddziala wzrosła o 15% w grudniu w porównaniu
do listopada. (Interpretacja jest ta sama co przyrostów względnych)

Objaśnienia w języku (*fixed-base index vs chain index*):
https://ec.europa.eu/eurostat/statistics-explained/index.php/Glossary:Chain_index 

**Średnie tempo zmian**

Coś w rodzaju średniej wartości indeksów; interpretowane jako przeciętna
zmiana wartości. Pierwiastek stopnia $N-1$  z iloczyny 
$P_{w1} \cdot P_{w2} \cdot ... \cdot P_{wN}$; takie 
coś nazywa się także **średnią geometryczną**.

Liczba pacjentów na oddziale w pierwszym półroczy rosła przeciętnie o 5%
z miesiąca na miesiąc.

## Indeksy agregatowe

Chcemy porównać zmiany wydatków na żywność. Prosta sprawa:
$W = w^1 + w^2 + ... + w^n$ gdzie $w^k$ ($k=1,...,n$) jest wartością wydatków
na określony produkt. Oczywiście $i_w = W_t/W_0$ będzie wskaźnikiem
dynamiki. Ale...

$W = p \cdot q$ (gdzie $p$ oznacza cenę a $q$ ilość):

$i_w = (q^1_t \cdot p^1_t + q^2_t \cdot p^2_t + ... q^n_t \cdot p^n_t) / (q^1_0 \cdot p^1_0 + q^2_0 \cdot p^2_0 + ... q^n_0 \cdot p^n_0)$

Albo używając znaku sumowania $\sum$:

$i_w = (\sum q_t * p_t) / (\sum q_0 * p_0)$

Jeżeli chcemy oszacować oddzielny wpływ zmian cen  i ilości to musimy przyjąć
stałą wielkość tego czynnika, którego wpływ chcemy pominąć. 

Przykładowo badając wpływ zmiany cen ustalamy jednakową wielkość ilości.

Dwa najcześciej stosowane sposoby 
to przyjęcie poziomu cen/ilości 
z okresu bazowego (indeks Laspeyresa; https://pl.wikipedia.org/wiki/%C3%89tienne_Laspeyres) 
lub badanego (indeks Paaschego; https://pl.wikipedia.org/wiki/Hermann_Paasche). 
Każdy z wariantów ma dwa indeksy: ilości i ceny.

Agregatowy indeks Laspeyresa ceny:

$I_p^L = (\sum q_0 \cdot p_t) / (\sum q_0 \cdot p_0) \cdot 100$

(zmienia się cena; ilość jest ta sama na poziomie okresu bazowego)

**Interpretacja**: odejmujemy od wartości $I_w$, $I_p$, $I_q$ 100%. Jeżeli
wartość jest mniejsza od zera interpretujemy jako spadek.

Przykładowo: przy założeniu, że ilości w okresie badanym są identyczne jak
w okresie podstawowym, wydatki na żywność wzrosły o x% z powodu zmiany cen.

Podobnie: przy założeniu, że ceny w okresie badanym są identyczne jak
w okresie podstawowym, wydatki 
na żywność wzrosły o x% z powodu zmiany ilości kupowanych produktów.

Można udowodnić że: $I_w = I_p^L \cdot I_q^P$ oraz
$I_w = I_p^P \cdot I_q^L$ (Indeks agregatowy jest  iloczynem indeksów 
ilości oraz ceny liczonych według różnych formuł)

## Wykresy

W przypadku szeregów czasowych wykres liniowy (ewentualnie punktowy lub słupkowy) 
jest najpopularniejszy. Przykład: 
z bazy danych WHO (https://www.who.int/data/gho) pobrano informacje nt odsetka
osób dorosłych z nadwagą (BMI 30 i więcej;  *Prevalence of obesity among adults...*)
dla Polski w latach 1975--2016.

Uwaga: WHO podaje wskaźniki surowe (*crude*) i standaryzowane; pobrano surowe

```{r, echo=FALSE, warning=FALSE, message=FALSE}
library("ggplot2")
library("dplyr")
library("tidyr")
library("scales")
obesity <- read.csv(file='obesity_POL.csv',sep=';',header=T)
```

Wykres liniowy

```{r, echo=FALSE}
popl <- ggplot(obesity, aes(x= as.Date(as.character(rok), "%Y"),
        ##group=as.factor(plec), color=as.factor(plec), 
        y=bmio )) +
  geom_line(size=.5, color='steelblue' ) +
  #geom_point(size=2.5, alpha=.3) +
  ylab(label="%") +
  xlab(label="") +
  scale_x_date(breaks = date_breaks("4 years"),  labels = date_format("%Y")) +
  #scale_color_discrete(name="Płeć", labels =c("M", 'F'),
  #                     breaks=c('MLE', 'FMLE')) +
  ggtitle("Nadwaga w PL w latach 1975--2016 (BMI30 ogółem)")
popl
```

Interpretacja: czy zjawisko rośnie czy spada; jak szybko rośnie jak
szybko spada. 

Uwaga: można manipulować wykresem poprzez zmianę proporcji (współczynnika proporcji czyli po angielsku **aspect ratio**)


```{r, echo=FALSE, fig.height=2.5}
popl.flat <- ggplot(obesity, aes(x= as.Date(as.character(rok), "%Y"),
        y=bmio )) +
  geom_line(size=.5, color='steelblue' ) +
  #geom_point(size=2.5, alpha=.3) +
  ylab(label="%") +
  xlab(label="") +
  scale_x_date(breaks = date_breaks("4 years"),  labels = date_format("%Y")) +
  ggtitle("Nadwaga w PL w latach 1975--2016 (BMI30 ogółem)")
popl.flat
```

Teraz (optycznie) wolniej rośnie (proporcja wysokość/szerokość jest większa)...

Oraz (albo raczej pośrednio) zakresem na osi OY; 

Jeżeli oś OY nie zaczyna się od zera to 
krzywa będzie bardziej stroma bo efektywnie wykres będzie miał większe
proporcje wysokość/szerokość:

```{r, echo=FALSE, fig.height=2.5}
popl.flat <- ggplot(obesity, aes(x= as.Date(as.character(rok), "%Y"),
        y=bmio )) +
  geom_line(size=.5, color='steelblue' ) +
  #geom_point(size=2.5, alpha=.3) +
  ylab(label="%") +
  xlab(label="") +
  scale_x_date(breaks = date_breaks("4 years"),  labels = date_format("%Y")) +
  coord_cartesian(ylim = c(0, NA)) +
  ggtitle("Nadwaga w PL w latach 1975--2016 (BMI30 ogółem)")
popl.flat
```

Puryści uważają że każdy wykres powinien zaczynać się od zera. Są przykłady
zeznań przed komisją senacją w USA gdzie dowody prezentowane na wykresach
**z niezerową linią bazową** były dyskwalifikowane jako manipulacja.

Słynna książka How to lie with statistics zawiera rozdział na temat
zatytułowany **The Gee-Whiz Graphs**; 
https://en.wikipedia.org/wiki/Misleading_graph


Można umieścić wiele krzywych celem porównania:


```{r, echo=FALSE}

popl2 <- ggplot(obesity, aes(x= as.Date(as.character(rok), "%Y"),
        y=bmio )) +
  geom_line(aes(y=bmik), size=.5, color = "pink" ) +
  geom_line(aes(y=bmim), size=.5, color = "steelblue" ) +
  #geom_point(size=2.5, alpha=.3) +
  ylab(label="%") +
  xlab(label="") +
   ##scale_x_discrete( breaks = every_nth(n = 4)) +
  scale_x_date(breaks = date_breaks("4 years"),  labels = date_format("%Y")) +
  #scale_color_discrete(name="Płeć", labels =c("M", 'F'),
  #                     breaks=c('MLE', 'FMLE')) +
  ggtitle("Nadwaga w PL w latach 1975--2016 (BMI30 ogółem)", 
          subtitle = "Według płci; różowe = K | niebieskie = M")
popl2
```

Jeżeli krzywe się **dobrze zachowują** (czytaj: nie przecinają się) na to sens;
w innym przypadku trudno jest porównać krzywe. Nie należy też przesadzać z liczbą
krzywych na wykresie. Na pewno coś co wygląda jak splątany makaron będzie
bezużyteczne...


Punktowy:

```{r, echo=FALSE}
popl <- ggplot(obesity, aes(x= as.Date(as.character(rok), "%Y"),
        ##group=as.factor(plec), color=as.factor(plec), 
        y=bmio )) +
  #geom_line(size=.5 ) +
  geom_point(size=1.25, color='steelblue' ) +
  ylab(label="%") +
  xlab(label="") +
  scale_x_date(breaks = date_breaks("4 years"),  labels = date_format("%Y")) +
  #scale_color_discrete(name="Płeć", labels =c("M", 'F'),
  #                     breaks=c('MLE', 'FMLE')) +
  ggtitle("Nadwaga w PL w latach 1975--2016 (BMI30 ogółem)")
popl
```

Nie uważam za dobry pomysł. Nie podkreśla ciągłości zjawisk w czasie

Słupkowy:

```{r, echo=FALSE}
popl <- ggplot(obesity, aes(x= as.factor(rok), y=bmio )) +
  #geom_line(size=.5 ) +
  geom_bar(stat="identity", position=position_dodge(width=.4), fill='steelblue' ) +
  ylab(label="%") +
  xlab(label="") +
   scale_x_discrete( breaks = every_nth(n = 4)) +
  #scale_color_discrete(name="Płeć", labels =c("M", 'F'),
  #                     breaks=c('MLE', 'FMLE')) +
  ggtitle("Nadwaga w PL w latach 1975--2016 (BMI30 ogółem)")
popl
```

Jest OK. Ale wielosłupki zamiast wielu linii prowadzą do problemów:

```{r, echo=FALSE}
ol <- obesity %>% 
  pivot_longer(cols=c(bmio, bmik, bmim), names_to='sex', values_to='bmi')
popl3 <- ggplot(ol, aes(fill=sex, y=bmi, x=as.factor(rok))) + 
   xlab(label="") +
   scale_x_discrete( breaks = every_nth(n = 4)) +
  geom_bar(position="dodge", stat="identity")

## albo
popl4 <- ggplot(ol, aes(fill=sex, y=bmi, x=as.factor(rok))) + 
   xlab(label="") +
   scale_x_discrete( breaks = every_nth(n = 4)) +
  geom_bar(position="stack", stat="identity")

popl3
popl4

```

Oba dla mnie nieczytelne a do tego ten drugi
 wykres daje mylne wrażenie że łącznie otyłych jest 3/4 ludności
(jak ktoś nieuważnie czyta)

## Model wahań w czasie

W szeregu czasowym można zwykle wyróżnić długookresową tendencję (trend);
powtarzalne wahania (sezonowość); resztę traktuje się jako wartości
przypadkowe. Reasumując:

$$TS = T + S + E$$

lub

$$TS = T \cdot S \cdot E$$

Pierwszy wariant nazywa się **addytywny** drugi **multiplikatywny**.
W wariancie addytywnym zmiany
(trendu/sezonowości) okres/okres są stałe; w wariancie multiplikatywnym **tempo zmiany** jest stałe, tj. zjawisko okres/okres rośnie/spada o x%. W jednostkach bezwzględnych
oznacza to, że rośnie/spada coraz szybciej.

Problem: oszacowanie T oraz S

## Szacowanie trendu

### metoda mechaniczna MA

Średnia ruchoma (moving average MA). Idea tego wygładzania
jest prosta: sumujemy kolejne wartości szeregu i dzielimy przez liczbę elementów
sumy (średnia $k$-okresowa); Ile elementów sumujemy jest dobieramy
metodą prób/błędów...

Przykład dzienne dane nt. liczby zgonów z powodu COVID 
(w okresie 1.10.2020--5.2.2021; źródło komunikaty MZ via Twitter 
a od 28.01.2021 https://www.gov.pl/web/koronawirus/wykaz-zarazen-koronawirusem-sars-cov-2; strona reklamowana przez Google!):

```{r, echo=FALSE, warning=FALSE, message=FALSE}

library("data.table")
covid <- read.csv(file='covidPL.csv',sep=';',header=T)
covidPL <- covid %>% filter(woj=='Polska')

cPL <- covidPL %>%  summarise(
  date = date,
  newd = newd,
  fmd3 = frollmean(newd, n=3, align='center'),
  fmd7 = frollmean(newd, n=7, align='center'),
  fmd14 = frollmean(newd, n=14, align='center'),
  fmd28 = frollmean(newd, n=28, align='center') )

pma1 <- ggplot(cPL, aes(x= as.Date(as.character(date), "%Y-%m-%d"),
                            y=fmd7 )) +
  geom_line(aes(y=fmd3), size=1, color = "orange" ) +
  geom_line(aes(y=fmd7), size=1, color = "pink" ) +
  geom_line(aes(y=fmd14), size=1, color = "red" ) +
  geom_line(aes(y=fmd28), size=1, color = "violet" ) +
  geom_point(aes(y=newd), size=.5, color = "black", alpha=.3 ) +
  geom_line(aes(y=newd), size=.2, color = "black", alpha=.3 ) +
  #geom_point(size=2.5, alpha=.3) +
  ylab(label="%") +
  xlab(label="") +
  #scale_color_discrete(name="Płeć", labels =c("M", 'F'),
  #                     breaks=c('MLE', 'FMLE')) +
  ggtitle("Zgony z powodu COVID w okresie 1.10.2020--5.2.2021")
pma1

```

Na powyższym wykresie mamy 4 średnie ruchome 3, 7, 14, 28 okresową. Średnia
trzy okresowa jest za mało wygładzona. Średnie 7, 14, 28 są podobne ale
każda kolejna jest krótsza.

Najlepsza średnia ruchoma: 7 okresów. (Dostatecznie wygładza 
trend i jest najdłuższa)

### metoda analityczna

Polega na dopasowaniu określonej funkcji matematycznej; w najprostszym przypadku
prostej przy użyciu metody najmniejszych kwadratów, czyli zakłada się że
trend jest postaci:

$$Y = a + b \cdot t + e$$

gdzie $e$ oznacza składnik losowy; Parametry $a$ i $b$ są wyznaczane w taki
sposób aby suma kwadratów różnic pomiędzy punktami na prostej a odpowiadającymi im
obserwacjami empirycznymi była jak najmniejsza. 
Wielkość tej sumy (lub pierwiastek kwadratowy z sumy) 
jest miarą dokładności dopasowania (wariancja składnika losowego;
albo średni błąd składnika losowego/resztowego--dla pierwiastka kwadratowego)

Udział wariancji składnika losowego w całości wariancji zmiennej $Y$ jest inną miarą
dopasowania (znaną jako współczynnik determinacji $\Phi^2$; por. wykład nt korelacji/regresji); 
im ten udział jest mniejszy tym lepiej (lub jeżeli współczynnik
zdefiniujemy jako 1 minus ww udział to im większy tym lepiej -- współczynnik
zbieżności czyli $R^2$)


**Przykład** Dane nt zgonów z powodu COVID w okresie 1.10.2020--5.2.2021
(linia niebieska trend dopasowany metodą NK)

```{r, echo=FALSE, warning=FALSE, message=FALSE}
popclm <- ggplot(covidPL, aes(x= as.Date(as.character(date), "%Y-%m-%d"),
                            y=newd )) +
  geom_line(aes(y=newd), size=.5, color = "pink" ) +
  geom_point(size=.9, color="red") +
  geom_smooth(method="lm", size=1.0, alpha=.3) +
  ylab(label="%") +
  xlab(label="") +
  ggtitle("Zgony z powodu COVID w okresie 1.10.2020--5.2.2021")
popclm
```



```{r, echo=FALSE}
trend = c (1:nrow(covidPL))
covidPL["trend"] <- trend

trendL.dPL <- lm(data=covidPL, newd ~ trend )
##summary(trendL.dPL)
lmc <- coef(trendL.dPL)
lmr <- summary(trendL.dPL)$r.squared
lmse <- summary(trendL.dPL)$sigma
Ymean <- mean(covidPL$newd)

##names(summary(trendL.dPL))

b.coeff <- lmc["trend"]
a.coeff <- lmc["(Intercept)"]
```

Współczynnik kierunkowy trendu liniowego wynoszący `r b.coeff` jest
interpretowany jako przeciętna zmiana z okresu na okres. Równanie prostej można
zapisać jako:

zgony = `r b.coeff` czas + `r a.coeff`

Interpretacja: **w omawianym okresie przeciętnie umierało 1,5 osoby więcej
dziennie**. Ale dopasowanie linii prostej do danych jest słabe co widać
oraz o czym świadczą wartości $R^2$ (`r lmr * 100`%, tj.  `r lmr * 100`% 
zmienności jest objaśniane przez model) oraz 
średni błąd składnika losowego $S_e$ (`r lmse`). Ten błąd warto
porówać do średniej wartości zmiennej objaśmnianej (liczby zgonów), która w omawianym okresie wynosi `r Ymean`. Zatem błąd jaki popełniamy stanowi
`r lmse/Ymean *100`% średniej. Dużo (coś jakby średnio 1 $\pm$ 0,6)


Inny przykład (nadwaga w PL):

```{r, echo=FALSE, warning=FALSE, message=FALSE}
popclm2 <- ggplot(obesity, aes(x= as.Date(as.character(rok), "%Y"), y=bmio )) +
  geom_line(size=.5, color='pink' ) +
  geom_point(size=.9, color='red', alpha=.3) +
  geom_smooth(method="lm", size=1.0, alpha=.3) +
  ylab(label="%") +
  xlab(label="") +
  ggtitle("Nadwaga w PL w latach 1975--2016 (BMI30 ogółem)")
  
popclm2
```

```{r, echo=FALSE}
trend = c (1:nrow(obesity))
obesity["trend"] <- trend

trendL.bmio <- lm(data=obesity, bmio ~ trend )
##summary(trendL.bmio)

lmc <- coef(trendL.bmio)
lmr <- summary(trendL.bmio)$r.squared
lmse <- summary(trendL.bmio)$sigma
Ymean <- mean(obesity$bmio)

##names(summary(trendL.dPL))

b.coeff <- lmc["trend"]
a.coeff <- lmc["(Intercept)"]

## kobiety
##trendL.bmik <- lm(data=obesity, bmik ~ trend )
##summary(trendL.bmik)
```


Współczynnik kierunkowy trendu liniowego wynoszący `r b.coeff` jest
interpretowany jako przeciętna zmiana z okresu na okres. Równanie prostej można
zapisać jako:

nadwaga = `r b.coeff` czas + `r a.coeff`

Interpretacja: **w omawianym okresie przeciętnie przybywało `r b.coeff`% osób 
z nadwagą rocznie**. Dopasowanie linii prostej do danych jest bardzo
dobre co widać
oraz o czym świadczą wartości $R^2$ (`r lmr * 100`%, tj.  `r lmr * 100`% 
zmienności jest objaśniane przez model) oraz 
średni błąd składnika losowego $S_e$ (`r lmse`). Ten błąd warto
porówać do średniej wartości zmiennej objaśmnianej (liczby zgonów), która w omawianym okresie wynosi `r Ymean`. Zatem błąd jaki popełniamy stanowi
`r lmse/Ymean *100`% średniej. 

## Szacowanie sezonowości

Plik `MZM.csv` zawiera dane miesięczne dotyczące liczby zwiedzających 
**Muzeum Zamkowe w Malborku**
w podziale
na ogółem oraz gości krajowych i zagranicznych. Przy czym podział na krajowych/zagranicznych jest mocno umowny--wg wyjaśnień pracownika MZM 
zwiedzający jest pytany przy zakupie biletu na tę okoliczność.

Dane zostały udostępnione przez biuro MZM w kwietniu 2019 roku.

```{r, echo=FALSE, warning=FALSE, message=FALSE}
z <- read.csv("MZM.csv", dec=".", sep = ',',  header=T, na.string="NA");

mzmp <- ggplot(z, aes(x= as.Date(miesiac), y=razem )) +
  geom_line(size=1, color='pink' ) +
  geom_point(size=1.5, color='red', alpha=.3) +
  geom_smooth(method="lm", size=1.0, alpha=.3) +
  ylab(label="%") +
  xlab(label="") +
  ggtitle("Liczba zwiedzających MZM")
  
mzmp
```

Szacujemy linię trendu liniowego





```{r, echo=FALSE}
z0 <- z %>% mutate (miesiac = as.factor(substr(miesiac, 6, 7)))
z0$miesiac <- relevel(z0$miesiac, ref="12")

trend = c (1:nrow(z0))
z0["trend"] <- trend

trend.mzm <- lm(data=z0, razem ~ trend)
lmc <- coef(trend.mzm)
lmr <- summary(trend.mzm)$r.squared
lmse <- summary(trend.mzm)$sigma
Ymean <- mean(z0$razem)

b.coeff <- lmc["trend"]
a.coeff <- lmc["(Intercept)"]

##summary(trend.mzm)
```


Interpretacja: **w omawianym okresie miesięczna liczba zwiedzających rosła
o `r b.coeff` osób**. Dopasowanie linii prostej jest bardzo słabe
($R^2$ = `r lmr * 100`% oraz $S_e$ = `r lmse`). 

Sezonowość uwzględniamy dodając do równania $d -1$ zmiennych zero-jedynkowych,
gdzie $d$ jest liczbą podokresów (dla danych kwartalnych $d=4$, 
dla miesięcznych $d=12$). Dla $k$-tej zmiennej zero-jedynkowej:

$z=1$ jeżeli podokres jest równy k, albo zero w każdej innej sytuacji

Czyli pierwsza zmienna zerojedynkowa będzie miała wartość 1 dla stycznia,
druga wartość 1 dla lutego itd...

Wygląda to dość pracochłonnie ale np. jeżeli korzystamy z Gretla jest
banalnie proste (Gretl sam się połapie ile wynosi $d$ i doda do równiania
tyle zmiennych ile trzeba i jeszcze je odpowiednio przekoduje)

Wynik jest taki:

```{r, echo=FALSE}
trend.mzm <- lm(data=z0, razem ~ trend + miesiac )

summary(trend.mzm)

lmc <- coef(trend.mzm)
lmr <- summary(trend.mzm)$r.squared
lmse <- summary(trend.mzm)$sigma
Ymean <- mean(z0$razem)

b.coeff <- lmc["trend"]
a.coeff <- lmc["(Intercept)"]

```

Interpretacja: **w omawianym okresie miesięczna liczba zwiedzających rosła
o `r b.coeff` osób**. Dopasowanie linii prostej jest znakomite
($R^2$ = `r lmr * 100`% oraz $S_e$ = `r lmse`). 

Przypominamy: do równania dodajemy $d-1$ zmiennych (jak dodamy $d$ to równanie nie da się oszacować); W powyższym przykładzie dodano zmienne styczeń--listopad
(`miesiac01`--`miesiac12`) a nie ma zmiennej grudzień.

Jeżeli wszystkie zmienne zero-jedynkowe mają wartość zero, to równanie opisuje
grudzień. Zatem interpretacja współczynników przy zmiennych
`miesiac01`--`miesiac12` sprowadza się do porównania względem grudnia, np.
W styczniu jest  przeciętnie 455.48 osób więcej niż w grudniu a  sierpniu
113808.97 osób więcej niż w grudniu. (Por wydruk powyżej)

Oczywiście jeżeli grudzień nam nie pasuje jako baza do
porównań możemy wybrać inny miesiąc czyli usunąć go z równania
a dodać zamiast niego grudzień.




 
